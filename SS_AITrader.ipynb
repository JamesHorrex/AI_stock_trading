{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SS_AITrader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUszqohqlvtMHfPR5gf398",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesHorrex/AI_stock_trading/blob/master/SS_AITrader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKT2tX6DtauA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fab20dad-e0d9-4cae-8347-2a9e8c797aaa"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2b2DdBskfka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7d70fb4f-0b83-43a0-b53a-2138c793ef0b"
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-0vomvxq2\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-0vomvxq2\n",
            "Requirement already satisfied (use --upgrade to upgrade): tensorflow-docs===0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774- from git+https://github.com/tensorflow/docs in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774-) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774-) (0.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774-) (3.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tensorflow-docs===0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774-) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->tensorflow-docs===0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774-) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorflow-docs===0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774-) (47.3.1)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0f82f2a94252f97efd2cdbc57408469e1d4cd9774_-cp36-none-any.whl size=119874 sha256=89ed793efb9c66990b53af5e65bf86589a8490908bab030b28e094c2287dd825\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rle7hdq4/wheels/eb/1b/35/fce87697be00d2fc63e0b4b395b0d9c7e391a10e98d9a0d97f\n",
            "Successfully built tensorflow-docs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYtw7-dbkYiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDdT5zKLv1rP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f27cbd8f-41f4-4496-8b99-f26bc4b581b4"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAz2vMeqAyTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "df=pd.read_csv('gdrive/My Drive/SS_AITrader/df_AAPL_w_macro.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0Qvmpz-BCSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "8dccf5e4-7055-4355-c182-dcfa7abdf1e6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>^vix</th>\n",
              "      <th>wr_5</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>wr_15</th>\n",
              "      <th>mfi_5</th>\n",
              "      <th>mfi_10</th>\n",
              "      <th>mfi_15</th>\n",
              "      <th>ppo</th>\n",
              "      <th>roc_5</th>\n",
              "      <th>roc_10</th>\n",
              "      <th>roc_15</th>\n",
              "      <th>cmf_5</th>\n",
              "      <th>cmf_10</th>\n",
              "      <th>cmf_15</th>\n",
              "      <th>cmo_5</th>\n",
              "      <th>cmo_10</th>\n",
              "      <th>cmo_15</th>\n",
              "      <th>close_sma_5</th>\n",
              "      <th>close_sma_10</th>\n",
              "      <th>close_sma_15</th>\n",
              "      <th>open_sma_5</th>\n",
              "      <th>open_sma_10</th>\n",
              "      <th>open_sma_15</th>\n",
              "      <th>ema_5</th>\n",
              "      <th>ema_10</th>\n",
              "      <th>ema_15</th>\n",
              "      <th>wma_5</th>\n",
              "      <th>wma_10</th>\n",
              "      <th>wma_15</th>\n",
              "      <th>hma_0</th>\n",
              "      <th>hma_1</th>\n",
              "      <th>hma_2</th>\n",
              "      <th>trix_5</th>\n",
              "      <th>trix_10</th>\n",
              "      <th>trix_15</th>\n",
              "      <th>cci_5</th>\n",
              "      <th>cci_10</th>\n",
              "      <th>cci_15</th>\n",
              "      <th>dpo_5</th>\n",
              "      <th>dpo_10</th>\n",
              "      <th>dpo_15</th>\n",
              "      <th>kst_5</th>\n",
              "      <th>kst_10</th>\n",
              "      <th>kst_15</th>\n",
              "      <th>dmi_5</th>\n",
              "      <th>dmi_10</th>\n",
              "      <th>dmi_15</th>\n",
              "      <th>bb_5</th>\n",
              "      <th>bb_10</th>\n",
              "      <th>bb_15</th>\n",
              "      <th>fi_5</th>\n",
              "      <th>fi_10</th>\n",
              "      <th>fi_15</th>\n",
              "      <th>rsv_5</th>\n",
              "      <th>kdjk_5</th>\n",
              "      <th>rsv_10</th>\n",
              "      <th>kdjk_10</th>\n",
              "      <th>rsv_15</th>\n",
              "      <th>kdjk_15</th>\n",
              "      <th>eom_5</th>\n",
              "      <th>eom_10</th>\n",
              "      <th>eom_15</th>\n",
              "      <th>volume_delta</th>\n",
              "      <th>high_minus_low</th>\n",
              "      <th>close_minus_open</th>\n",
              "      <th>close_to_close</th>\n",
              "      <th>curve</th>\n",
              "      <th>curve_shift</th>\n",
              "      <th>^irx_change</th>\n",
              "      <th>^tnx_change</th>\n",
              "      <th>^vix_change</th>\n",
              "      <th>cny=x_change</th>\n",
              "      <th>jpy=x_change</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-23</td>\n",
              "      <td>16.660000</td>\n",
              "      <td>-9.005805</td>\n",
              "      <td>-9.005805</td>\n",
              "      <td>-8.442943</td>\n",
              "      <td>72.465975</td>\n",
              "      <td>57.971669</td>\n",
              "      <td>50.526604</td>\n",
              "      <td>0.323010</td>\n",
              "      <td>5.766714</td>\n",
              "      <td>0.974175</td>\n",
              "      <td>2.355505</td>\n",
              "      <td>0.269409</td>\n",
              "      <td>-0.026337</td>\n",
              "      <td>0.035697</td>\n",
              "      <td>78.772</td>\n",
              "      <td>7.233</td>\n",
              "      <td>10.467</td>\n",
              "      <td>109.928001</td>\n",
              "      <td>109.774001</td>\n",
              "      <td>109.281334</td>\n",
              "      <td>109.275999</td>\n",
              "      <td>110.212000</td>\n",
              "      <td>109.651333</td>\n",
              "      <td>110.923227</td>\n",
              "      <td>110.099342</td>\n",
              "      <td>109.823204</td>\n",
              "      <td>111.105335</td>\n",
              "      <td>109.986365</td>\n",
              "      <td>109.741751</td>\n",
              "      <td>114.052892</td>\n",
              "      <td>110.725305</td>\n",
              "      <td>142.153977</td>\n",
              "      <td>0.211160</td>\n",
              "      <td>-0.018010</td>\n",
              "      <td>-0.033946</td>\n",
              "      <td>103.757607</td>\n",
              "      <td>124.750463</td>\n",
              "      <td>133.500352</td>\n",
              "      <td>-1.208000</td>\n",
              "      <td>0.026002</td>\n",
              "      <td>-0.031334</td>\n",
              "      <td>-293.843045</td>\n",
              "      <td>-307.413795</td>\n",
              "      <td>-324.626496</td>\n",
              "      <td>23.314219</td>\n",
              "      <td>29.071140</td>\n",
              "      <td>33.532915</td>\n",
              "      <td>109.928001</td>\n",
              "      <td>109.774001</td>\n",
              "      <td>109.281334</td>\n",
              "      <td>5.040429e+07</td>\n",
              "      <td>5.040429e+07</td>\n",
              "      <td>5.040429e+07</td>\n",
              "      <td>90.994195</td>\n",
              "      <td>72.878272</td>\n",
              "      <td>90.994195</td>\n",
              "      <td>70.335449</td>\n",
              "      <td>91.557057</td>\n",
              "      <td>71.128494</td>\n",
              "      <td>7.381712</td>\n",
              "      <td>7.381712</td>\n",
              "      <td>7.381712</td>\n",
              "      <td>-7331600.0</td>\n",
              "      <td>0.019650</td>\n",
              "      <td>0.006055</td>\n",
              "      <td>0.005160</td>\n",
              "      <td>1.804</td>\n",
              "      <td>-1.077</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>-0.000435</td>\n",
              "      <td>0.007560</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-26</td>\n",
              "      <td>15.520000</td>\n",
              "      <td>-16.030560</td>\n",
              "      <td>-13.755476</td>\n",
              "      <td>-12.949658</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>58.179270</td>\n",
              "      <td>57.108232</td>\n",
              "      <td>0.466025</td>\n",
              "      <td>6.708181</td>\n",
              "      <td>0.973124</td>\n",
              "      <td>3.448273</td>\n",
              "      <td>0.262863</td>\n",
              "      <td>-0.105227</td>\n",
              "      <td>-0.003052</td>\n",
              "      <td>100.000</td>\n",
              "      <td>7.233</td>\n",
              "      <td>15.767</td>\n",
              "      <td>111.350002</td>\n",
              "      <td>109.883001</td>\n",
              "      <td>109.532668</td>\n",
              "      <td>110.617999</td>\n",
              "      <td>110.318999</td>\n",
              "      <td>109.808000</td>\n",
              "      <td>111.649554</td>\n",
              "      <td>110.663532</td>\n",
              "      <td>110.279994</td>\n",
              "      <td>112.162668</td>\n",
              "      <td>110.591092</td>\n",
              "      <td>110.219084</td>\n",
              "      <td>114.127556</td>\n",
              "      <td>112.603729</td>\n",
              "      <td>121.421460</td>\n",
              "      <td>0.339265</td>\n",
              "      <td>0.022707</td>\n",
              "      <td>-0.019595</td>\n",
              "      <td>87.350131</td>\n",
              "      <td>132.828930</td>\n",
              "      <td>132.296306</td>\n",
              "      <td>-1.799998</td>\n",
              "      <td>-3.063001</td>\n",
              "      <td>0.687334</td>\n",
              "      <td>-285.519144</td>\n",
              "      <td>-296.218423</td>\n",
              "      <td>-313.183608</td>\n",
              "      <td>24.980228</td>\n",
              "      <td>28.925920</td>\n",
              "      <td>32.791890</td>\n",
              "      <td>111.350002</td>\n",
              "      <td>109.883001</td>\n",
              "      <td>109.532668</td>\n",
              "      <td>3.582737e+07</td>\n",
              "      <td>3.582737e+07</td>\n",
              "      <td>3.582737e+07</td>\n",
              "      <td>83.969440</td>\n",
              "      <td>76.575328</td>\n",
              "      <td>86.244524</td>\n",
              "      <td>75.638474</td>\n",
              "      <td>87.050342</td>\n",
              "      <td>76.435777</td>\n",
              "      <td>2.636701</td>\n",
              "      <td>2.636701</td>\n",
              "      <td>2.636701</td>\n",
              "      <td>9150200.0</td>\n",
              "      <td>0.013793</td>\n",
              "      <td>-0.005627</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>1.823</td>\n",
              "      <td>-0.981</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-1.139999</td>\n",
              "      <td>0.003049</td>\n",
              "      <td>-0.011705</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-27</td>\n",
              "      <td>17.219999</td>\n",
              "      <td>-85.714250</td>\n",
              "      <td>-56.986890</td>\n",
              "      <td>-53.648504</td>\n",
              "      <td>68.468290</td>\n",
              "      <td>53.745445</td>\n",
              "      <td>54.919817</td>\n",
              "      <td>0.343820</td>\n",
              "      <td>0.386312</td>\n",
              "      <td>-0.100687</td>\n",
              "      <td>2.719999</td>\n",
              "      <td>-0.208030</td>\n",
              "      <td>-0.182414</td>\n",
              "      <td>-0.069969</td>\n",
              "      <td>5.036</td>\n",
              "      <td>-0.676</td>\n",
              "      <td>11.658</td>\n",
              "      <td>111.434001</td>\n",
              "      <td>109.872001</td>\n",
              "      <td>109.725334</td>\n",
              "      <td>111.534000</td>\n",
              "      <td>110.300999</td>\n",
              "      <td>110.083333</td>\n",
              "      <td>110.812470</td>\n",
              "      <td>110.378840</td>\n",
              "      <td>110.123333</td>\n",
              "      <td>111.426000</td>\n",
              "      <td>110.456001</td>\n",
              "      <td>110.170001</td>\n",
              "      <td>110.981776</td>\n",
              "      <td>112.813466</td>\n",
              "      <td>111.103207</td>\n",
              "      <td>0.272731</td>\n",
              "      <td>0.040895</td>\n",
              "      <td>-0.010339</td>\n",
              "      <td>-67.849364</td>\n",
              "      <td>8.592128</td>\n",
              "      <td>16.665564</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>-3.882003</td>\n",
              "      <td>0.074669</td>\n",
              "      <td>-278.036210</td>\n",
              "      <td>-285.134427</td>\n",
              "      <td>-301.817544</td>\n",
              "      <td>24.032144</td>\n",
              "      <td>27.649804</td>\n",
              "      <td>31.306843</td>\n",
              "      <td>111.434001</td>\n",
              "      <td>109.872001</td>\n",
              "      <td>109.725334</td>\n",
              "      <td>-1.022657e+08</td>\n",
              "      <td>-1.022657e+08</td>\n",
              "      <td>-1.022657e+08</td>\n",
              "      <td>14.285750</td>\n",
              "      <td>55.812135</td>\n",
              "      <td>43.013110</td>\n",
              "      <td>64.763353</td>\n",
              "      <td>46.351496</td>\n",
              "      <td>66.407683</td>\n",
              "      <td>-10.198177</td>\n",
              "      <td>-10.198177</td>\n",
              "      <td>-10.198177</td>\n",
              "      <td>39953700.0</td>\n",
              "      <td>0.031611</td>\n",
              "      <td>-0.029176</td>\n",
              "      <td>-0.035013</td>\n",
              "      <td>1.807</td>\n",
              "      <td>-1.016</td>\n",
              "      <td>0.013</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>1.699999</td>\n",
              "      <td>0.004487</td>\n",
              "      <td>0.009875</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-28</td>\n",
              "      <td>20.440001</td>\n",
              "      <td>-30.913135</td>\n",
              "      <td>-21.749256</td>\n",
              "      <td>-21.749256</td>\n",
              "      <td>76.648565</td>\n",
              "      <td>59.590262</td>\n",
              "      <td>65.798643</td>\n",
              "      <td>0.602797</td>\n",
              "      <td>5.257868</td>\n",
              "      <td>4.618033</td>\n",
              "      <td>8.516841</td>\n",
              "      <td>-0.514890</td>\n",
              "      <td>-0.343395</td>\n",
              "      <td>-0.228957</td>\n",
              "      <td>42.105</td>\n",
              "      <td>23.707</td>\n",
              "      <td>29.241</td>\n",
              "      <td>112.586000</td>\n",
              "      <td>110.381001</td>\n",
              "      <td>110.328667</td>\n",
              "      <td>113.270000</td>\n",
              "      <td>110.920999</td>\n",
              "      <td>110.822666</td>\n",
              "      <td>112.312322</td>\n",
              "      <td>111.295665</td>\n",
              "      <td>110.827351</td>\n",
              "      <td>112.717999</td>\n",
              "      <td>111.444727</td>\n",
              "      <td>110.868084</td>\n",
              "      <td>112.357108</td>\n",
              "      <td>113.416676</td>\n",
              "      <td>112.051109</td>\n",
              "      <td>0.364361</td>\n",
              "      <td>0.078750</td>\n",
              "      <td>0.006096</td>\n",
              "      <td>142.222208</td>\n",
              "      <td>161.758811</td>\n",
              "      <td>204.235526</td>\n",
              "      <td>0.394003</td>\n",
              "      <td>-1.660999</td>\n",
              "      <td>-3.508668</td>\n",
              "      <td>-267.170503</td>\n",
              "      <td>-270.651513</td>\n",
              "      <td>-286.944750</td>\n",
              "      <td>24.318434</td>\n",
              "      <td>27.134181</td>\n",
              "      <td>30.425085</td>\n",
              "      <td>112.586000</td>\n",
              "      <td>110.381001</td>\n",
              "      <td>110.328667</td>\n",
              "      <td>2.330773e+08</td>\n",
              "      <td>2.330773e+08</td>\n",
              "      <td>2.330773e+08</td>\n",
              "      <td>69.086865</td>\n",
              "      <td>60.237045</td>\n",
              "      <td>78.250744</td>\n",
              "      <td>69.259150</td>\n",
              "      <td>78.250744</td>\n",
              "      <td>70.355370</td>\n",
              "      <td>11.433615</td>\n",
              "      <td>11.433615</td>\n",
              "      <td>11.433615</td>\n",
              "      <td>50908400.0</td>\n",
              "      <td>0.024369</td>\n",
              "      <td>-0.019723</td>\n",
              "      <td>0.056533</td>\n",
              "      <td>1.709</td>\n",
              "      <td>-1.098</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.101</td>\n",
              "      <td>3.220001</td>\n",
              "      <td>-0.001713</td>\n",
              "      <td>-0.006286</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-29</td>\n",
              "      <td>18.760000</td>\n",
              "      <td>-2.854339</td>\n",
              "      <td>-2.072915</td>\n",
              "      <td>-2.072915</td>\n",
              "      <td>78.530401</td>\n",
              "      <td>68.548221</td>\n",
              "      <td>67.529590</td>\n",
              "      <td>1.001082</td>\n",
              "      <td>5.782918</td>\n",
              "      <td>8.287794</td>\n",
              "      <td>10.348029</td>\n",
              "      <td>-0.431673</td>\n",
              "      <td>-0.248697</td>\n",
              "      <td>-0.163782</td>\n",
              "      <td>45.076</td>\n",
              "      <td>36.932</td>\n",
              "      <td>33.737</td>\n",
              "      <td>113.886000</td>\n",
              "      <td>111.291000</td>\n",
              "      <td>111.072001</td>\n",
              "      <td>114.481999</td>\n",
              "      <td>111.648999</td>\n",
              "      <td>111.430666</td>\n",
              "      <td>114.508876</td>\n",
              "      <td>112.703717</td>\n",
              "      <td>111.911462</td>\n",
              "      <td>114.822666</td>\n",
              "      <td>112.993637</td>\n",
              "      <td>111.939500</td>\n",
              "      <td>118.318888</td>\n",
              "      <td>115.055605</td>\n",
              "      <td>113.615311</td>\n",
              "      <td>0.584832</td>\n",
              "      <td>0.143210</td>\n",
              "      <td>0.033003</td>\n",
              "      <td>106.364237</td>\n",
              "      <td>145.277739</td>\n",
              "      <td>200.347092</td>\n",
              "      <td>-0.786002</td>\n",
              "      <td>-1.740997</td>\n",
              "      <td>-5.082003</td>\n",
              "      <td>-254.582319</td>\n",
              "      <td>-254.288569</td>\n",
              "      <td>-270.375781</td>\n",
              "      <td>25.640510</td>\n",
              "      <td>27.347751</td>\n",
              "      <td>30.134310</td>\n",
              "      <td>113.886000</td>\n",
              "      <td>111.291000</td>\n",
              "      <td>111.072001</td>\n",
              "      <td>2.564272e+08</td>\n",
              "      <td>2.564272e+08</td>\n",
              "      <td>2.564272e+08</td>\n",
              "      <td>97.145661</td>\n",
              "      <td>72.539917</td>\n",
              "      <td>97.927085</td>\n",
              "      <td>78.815128</td>\n",
              "      <td>97.927085</td>\n",
              "      <td>79.545942</td>\n",
              "      <td>2.837405</td>\n",
              "      <td>2.837405</td>\n",
              "      <td>2.837405</td>\n",
              "      <td>-62040700.0</td>\n",
              "      <td>0.030530</td>\n",
              "      <td>0.022180</td>\n",
              "      <td>0.031133</td>\n",
              "      <td>1.741</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>0.027</td>\n",
              "      <td>-1.680000</td>\n",
              "      <td>0.000225</td>\n",
              "      <td>-0.001554</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    timestamp       ^vix       wr_5  ...  cny=x_change  jpy=x_change  labels\n",
              "0  2015-01-23  16.660000  -9.005805  ...     -0.000435      0.007560     2.0\n",
              "1  2015-01-26  15.520000 -16.030560  ...      0.003049     -0.011705     0.0\n",
              "2  2015-01-27  17.219999 -85.714250  ...      0.004487      0.009875     1.0\n",
              "3  2015-01-28  20.440001 -30.913135  ...     -0.001713     -0.006286     1.0\n",
              "4  2015-01-29  18.760000  -2.854339  ...      0.000225     -0.001554     0.0\n",
              "\n",
              "[5 rows x 75 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR7WRpTJaRB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['timestamp'], inplace=True, axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anb_cU4SHzkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = df.sample(frac=0.8,random_state=0)\n",
        "test_dataset = df.drop(train_dataset.index)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ze7LKS-ak6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "fd52c1b5-c746-4e6b-e9be-aaec788dee9b"
      },
      "source": [
        "train_dataset.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>^vix</th>\n",
              "      <th>wr_5</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>wr_15</th>\n",
              "      <th>mfi_5</th>\n",
              "      <th>mfi_10</th>\n",
              "      <th>mfi_15</th>\n",
              "      <th>ppo</th>\n",
              "      <th>roc_5</th>\n",
              "      <th>roc_10</th>\n",
              "      <th>roc_15</th>\n",
              "      <th>cmf_5</th>\n",
              "      <th>cmf_10</th>\n",
              "      <th>cmf_15</th>\n",
              "      <th>cmo_5</th>\n",
              "      <th>cmo_10</th>\n",
              "      <th>cmo_15</th>\n",
              "      <th>close_sma_5</th>\n",
              "      <th>close_sma_10</th>\n",
              "      <th>close_sma_15</th>\n",
              "      <th>open_sma_5</th>\n",
              "      <th>open_sma_10</th>\n",
              "      <th>open_sma_15</th>\n",
              "      <th>ema_5</th>\n",
              "      <th>ema_10</th>\n",
              "      <th>ema_15</th>\n",
              "      <th>wma_5</th>\n",
              "      <th>wma_10</th>\n",
              "      <th>wma_15</th>\n",
              "      <th>hma_0</th>\n",
              "      <th>hma_1</th>\n",
              "      <th>hma_2</th>\n",
              "      <th>trix_5</th>\n",
              "      <th>trix_10</th>\n",
              "      <th>trix_15</th>\n",
              "      <th>cci_5</th>\n",
              "      <th>cci_10</th>\n",
              "      <th>cci_15</th>\n",
              "      <th>dpo_5</th>\n",
              "      <th>dpo_10</th>\n",
              "      <th>dpo_15</th>\n",
              "      <th>kst_5</th>\n",
              "      <th>kst_10</th>\n",
              "      <th>kst_15</th>\n",
              "      <th>dmi_5</th>\n",
              "      <th>dmi_10</th>\n",
              "      <th>dmi_15</th>\n",
              "      <th>bb_5</th>\n",
              "      <th>bb_10</th>\n",
              "      <th>bb_15</th>\n",
              "      <th>fi_5</th>\n",
              "      <th>fi_10</th>\n",
              "      <th>fi_15</th>\n",
              "      <th>rsv_5</th>\n",
              "      <th>kdjk_5</th>\n",
              "      <th>rsv_10</th>\n",
              "      <th>kdjk_10</th>\n",
              "      <th>rsv_15</th>\n",
              "      <th>kdjk_15</th>\n",
              "      <th>eom_5</th>\n",
              "      <th>eom_10</th>\n",
              "      <th>eom_15</th>\n",
              "      <th>volume_delta</th>\n",
              "      <th>high_minus_low</th>\n",
              "      <th>close_minus_open</th>\n",
              "      <th>close_to_close</th>\n",
              "      <th>curve</th>\n",
              "      <th>curve_shift</th>\n",
              "      <th>^irx_change</th>\n",
              "      <th>^tnx_change</th>\n",
              "      <th>^vix_change</th>\n",
              "      <th>cny=x_change</th>\n",
              "      <th>jpy=x_change</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>13.740000</td>\n",
              "      <td>-49.967445</td>\n",
              "      <td>-34.549546</td>\n",
              "      <td>-30.173087</td>\n",
              "      <td>77.348662</td>\n",
              "      <td>78.697020</td>\n",
              "      <td>64.807860</td>\n",
              "      <td>1.898898</td>\n",
              "      <td>2.574325</td>\n",
              "      <td>4.660067</td>\n",
              "      <td>2.960554</td>\n",
              "      <td>0.263309</td>\n",
              "      <td>0.239783</td>\n",
              "      <td>0.127906</td>\n",
              "      <td>36.190</td>\n",
              "      <td>37.347</td>\n",
              "      <td>13.403</td>\n",
              "      <td>219.259998</td>\n",
              "      <td>214.646999</td>\n",
              "      <td>211.619999</td>\n",
              "      <td>218.314001</td>\n",
              "      <td>214.260001</td>\n",
              "      <td>211.890000</td>\n",
              "      <td>218.879971</td>\n",
              "      <td>215.932147</td>\n",
              "      <td>213.871256</td>\n",
              "      <td>220.296664</td>\n",
              "      <td>217.328725</td>\n",
              "      <td>214.839165</td>\n",
              "      <td>222.201999</td>\n",
              "      <td>223.103168</td>\n",
              "      <td>220.616605</td>\n",
              "      <td>0.660100</td>\n",
              "      <td>0.308656</td>\n",
              "      <td>0.180381</td>\n",
              "      <td>2.578989</td>\n",
              "      <td>67.401194</td>\n",
              "      <td>93.408531</td>\n",
              "      <td>-2.560001</td>\n",
              "      <td>-1.367000</td>\n",
              "      <td>-5.920002</td>\n",
              "      <td>40.055364</td>\n",
              "      <td>40.000234</td>\n",
              "      <td>40.601764</td>\n",
              "      <td>34.427781</td>\n",
              "      <td>29.663715</td>\n",
              "      <td>27.898671</td>\n",
              "      <td>219.259998</td>\n",
              "      <td>214.646999</td>\n",
              "      <td>211.619999</td>\n",
              "      <td>-2.949592e+06</td>\n",
              "      <td>-2.949592e+06</td>\n",
              "      <td>-2.949592e+06</td>\n",
              "      <td>50.032555</td>\n",
              "      <td>74.084679</td>\n",
              "      <td>65.450454</td>\n",
              "      <td>80.388903</td>\n",
              "      <td>69.826913</td>\n",
              "      <td>82.781229</td>\n",
              "      <td>-54.373981</td>\n",
              "      <td>-54.373981</td>\n",
              "      <td>-54.373981</td>\n",
              "      <td>7536600.0</td>\n",
              "      <td>0.017234</td>\n",
              "      <td>-0.005682</td>\n",
              "      <td>-0.019454</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.893</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.112</td>\n",
              "      <td>-0.480000</td>\n",
              "      <td>-0.005256</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>16.190001</td>\n",
              "      <td>-91.881121</td>\n",
              "      <td>-91.881121</td>\n",
              "      <td>-92.379121</td>\n",
              "      <td>34.703351</td>\n",
              "      <td>37.398926</td>\n",
              "      <td>54.302483</td>\n",
              "      <td>0.891279</td>\n",
              "      <td>-2.469981</td>\n",
              "      <td>-3.323979</td>\n",
              "      <td>-0.149265</td>\n",
              "      <td>0.333082</td>\n",
              "      <td>0.248059</td>\n",
              "      <td>0.069919</td>\n",
              "      <td>-46.602</td>\n",
              "      <td>-54.230</td>\n",
              "      <td>-1.457</td>\n",
              "      <td>115.938000</td>\n",
              "      <td>116.549001</td>\n",
              "      <td>116.520000</td>\n",
              "      <td>115.723999</td>\n",
              "      <td>116.505000</td>\n",
              "      <td>116.605332</td>\n",
              "      <td>115.292804</td>\n",
              "      <td>115.832148</td>\n",
              "      <td>115.715698</td>\n",
              "      <td>115.162667</td>\n",
              "      <td>116.017819</td>\n",
              "      <td>116.359834</td>\n",
              "      <td>113.058003</td>\n",
              "      <td>115.147334</td>\n",
              "      <td>116.132105</td>\n",
              "      <td>-0.154700</td>\n",
              "      <td>0.149546</td>\n",
              "      <td>0.204501</td>\n",
              "      <td>-76.751639</td>\n",
              "      <td>-135.788569</td>\n",
              "      <td>-141.855791</td>\n",
              "      <td>2.312000</td>\n",
              "      <td>0.510997</td>\n",
              "      <td>0.950001</td>\n",
              "      <td>47.788855</td>\n",
              "      <td>49.587277</td>\n",
              "      <td>51.121123</td>\n",
              "      <td>25.589288</td>\n",
              "      <td>26.447036</td>\n",
              "      <td>26.881509</td>\n",
              "      <td>115.938000</td>\n",
              "      <td>116.549001</td>\n",
              "      <td>116.520000</td>\n",
              "      <td>-3.993176e+07</td>\n",
              "      <td>-3.993176e+07</td>\n",
              "      <td>-3.993176e+07</td>\n",
              "      <td>8.118879</td>\n",
              "      <td>39.043902</td>\n",
              "      <td>8.118879</td>\n",
              "      <td>38.552197</td>\n",
              "      <td>7.620879</td>\n",
              "      <td>39.661511</td>\n",
              "      <td>-3.021534</td>\n",
              "      <td>-3.021534</td>\n",
              "      <td>-3.021534</td>\n",
              "      <td>3299700.0</td>\n",
              "      <td>0.015477</td>\n",
              "      <td>-0.001317</td>\n",
              "      <td>-0.006639</td>\n",
              "      <td>1.572</td>\n",
              "      <td>-0.996</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.830001</td>\n",
              "      <td>0.002231</td>\n",
              "      <td>0.006178</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>13.350000</td>\n",
              "      <td>-16.262486</td>\n",
              "      <td>-23.167597</td>\n",
              "      <td>-50.169816</td>\n",
              "      <td>52.636288</td>\n",
              "      <td>43.944417</td>\n",
              "      <td>30.433928</td>\n",
              "      <td>-1.316411</td>\n",
              "      <td>-0.838745</td>\n",
              "      <td>-1.469665</td>\n",
              "      <td>-4.879314</td>\n",
              "      <td>0.225553</td>\n",
              "      <td>0.250470</td>\n",
              "      <td>0.030704</td>\n",
              "      <td>-9.800</td>\n",
              "      <td>-11.202</td>\n",
              "      <td>-29.936</td>\n",
              "      <td>108.109999</td>\n",
              "      <td>109.156999</td>\n",
              "      <td>110.425999</td>\n",
              "      <td>108.375998</td>\n",
              "      <td>109.165999</td>\n",
              "      <td>110.628666</td>\n",
              "      <td>109.096052</td>\n",
              "      <td>109.673730</td>\n",
              "      <td>110.466315</td>\n",
              "      <td>108.683332</td>\n",
              "      <td>108.915999</td>\n",
              "      <td>109.455666</td>\n",
              "      <td>110.804886</td>\n",
              "      <td>107.807797</td>\n",
              "      <td>107.690849</td>\n",
              "      <td>-0.302262</td>\n",
              "      <td>-0.323479</td>\n",
              "      <td>-0.139691</td>\n",
              "      <td>96.489297</td>\n",
              "      <td>38.640341</td>\n",
              "      <td>-24.595085</td>\n",
              "      <td>-2.400000</td>\n",
              "      <td>1.902998</td>\n",
              "      <td>-1.586003</td>\n",
              "      <td>-44.296611</td>\n",
              "      <td>-47.181630</td>\n",
              "      <td>-48.983537</td>\n",
              "      <td>53.138972</td>\n",
              "      <td>52.050359</td>\n",
              "      <td>49.114338</td>\n",
              "      <td>108.109999</td>\n",
              "      <td>109.156999</td>\n",
              "      <td>110.425999</td>\n",
              "      <td>2.147963e+07</td>\n",
              "      <td>2.147963e+07</td>\n",
              "      <td>2.147963e+07</td>\n",
              "      <td>83.737514</td>\n",
              "      <td>63.039833</td>\n",
              "      <td>76.832403</td>\n",
              "      <td>52.688880</td>\n",
              "      <td>49.830184</td>\n",
              "      <td>36.009972</td>\n",
              "      <td>6.463502</td>\n",
              "      <td>6.463502</td>\n",
              "      <td>6.463502</td>\n",
              "      <td>-31208500.0</td>\n",
              "      <td>0.013824</td>\n",
              "      <td>0.001275</td>\n",
              "      <td>-0.000364</td>\n",
              "      <td>1.856</td>\n",
              "      <td>-0.914</td>\n",
              "      <td>-0.033</td>\n",
              "      <td>0.053</td>\n",
              "      <td>-0.370000</td>\n",
              "      <td>-0.010047</td>\n",
              "      <td>-0.002320</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>22.340000</td>\n",
              "      <td>-0.497524</td>\n",
              "      <td>-0.497524</td>\n",
              "      <td>-41.219694</td>\n",
              "      <td>53.344641</td>\n",
              "      <td>43.893538</td>\n",
              "      <td>28.719193</td>\n",
              "      <td>-3.421902</td>\n",
              "      <td>1.909166</td>\n",
              "      <td>5.152930</td>\n",
              "      <td>-5.497579</td>\n",
              "      <td>0.360456</td>\n",
              "      <td>0.105475</td>\n",
              "      <td>-0.044847</td>\n",
              "      <td>22.093</td>\n",
              "      <td>29.566</td>\n",
              "      <td>-21.177</td>\n",
              "      <td>97.660001</td>\n",
              "      <td>98.066000</td>\n",
              "      <td>99.408666</td>\n",
              "      <td>97.079999</td>\n",
              "      <td>98.175000</td>\n",
              "      <td>99.757333</td>\n",
              "      <td>98.535227</td>\n",
              "      <td>98.962607</td>\n",
              "      <td>100.142585</td>\n",
              "      <td>98.208001</td>\n",
              "      <td>98.103273</td>\n",
              "      <td>98.401000</td>\n",
              "      <td>99.512000</td>\n",
              "      <td>97.364143</td>\n",
              "      <td>96.971662</td>\n",
              "      <td>-0.282359</td>\n",
              "      <td>-0.596240</td>\n",
              "      <td>-0.530609</td>\n",
              "      <td>166.666667</td>\n",
              "      <td>137.025752</td>\n",
              "      <td>26.601618</td>\n",
              "      <td>-0.999997</td>\n",
              "      <td>-0.676000</td>\n",
              "      <td>-0.878667</td>\n",
              "      <td>-116.812768</td>\n",
              "      <td>-121.148423</td>\n",
              "      <td>-123.898601</td>\n",
              "      <td>51.111369</td>\n",
              "      <td>53.000176</td>\n",
              "      <td>52.468258</td>\n",
              "      <td>97.660001</td>\n",
              "      <td>98.066000</td>\n",
              "      <td>99.408666</td>\n",
              "      <td>9.389201e+07</td>\n",
              "      <td>9.389201e+07</td>\n",
              "      <td>9.389201e+07</td>\n",
              "      <td>99.502476</td>\n",
              "      <td>58.248013</td>\n",
              "      <td>99.502476</td>\n",
              "      <td>51.994836</td>\n",
              "      <td>58.780306</td>\n",
              "      <td>30.963008</td>\n",
              "      <td>16.459511</td>\n",
              "      <td>16.459511</td>\n",
              "      <td>16.459511</td>\n",
              "      <td>13639000.0</td>\n",
              "      <td>0.030467</td>\n",
              "      <td>0.028288</td>\n",
              "      <td>0.053167</td>\n",
              "      <td>1.760</td>\n",
              "      <td>-0.986</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.029</td>\n",
              "      <td>-4.350000</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.006744</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>16.049999</td>\n",
              "      <td>-35.115093</td>\n",
              "      <td>-35.115093</td>\n",
              "      <td>-35.115093</td>\n",
              "      <td>41.962637</td>\n",
              "      <td>50.398234</td>\n",
              "      <td>46.920761</td>\n",
              "      <td>2.335417</td>\n",
              "      <td>0.365137</td>\n",
              "      <td>0.720219</td>\n",
              "      <td>0.596294</td>\n",
              "      <td>0.067664</td>\n",
              "      <td>0.078555</td>\n",
              "      <td>0.041191</td>\n",
              "      <td>3.567</td>\n",
              "      <td>4.207</td>\n",
              "      <td>2.725</td>\n",
              "      <td>317.046002</td>\n",
              "      <td>316.711005</td>\n",
              "      <td>316.111336</td>\n",
              "      <td>317.106000</td>\n",
              "      <td>316.494000</td>\n",
              "      <td>316.036001</td>\n",
              "      <td>315.637861</td>\n",
              "      <td>315.409416</td>\n",
              "      <td>313.694968</td>\n",
              "      <td>315.300004</td>\n",
              "      <td>316.199822</td>\n",
              "      <td>316.378254</td>\n",
              "      <td>311.492896</td>\n",
              "      <td>314.581569</td>\n",
              "      <td>316.279739</td>\n",
              "      <td>-0.032331</td>\n",
              "      <td>0.320679</td>\n",
              "      <td>0.449566</td>\n",
              "      <td>2.934820</td>\n",
              "      <td>11.701300</td>\n",
              "      <td>23.986806</td>\n",
              "      <td>6.823993</td>\n",
              "      <td>-7.760992</td>\n",
              "      <td>3.118675</td>\n",
              "      <td>106.356690</td>\n",
              "      <td>107.796533</td>\n",
              "      <td>110.916645</td>\n",
              "      <td>27.268141</td>\n",
              "      <td>35.671296</td>\n",
              "      <td>40.656925</td>\n",
              "      <td>317.046002</td>\n",
              "      <td>316.711005</td>\n",
              "      <td>316.111336</td>\n",
              "      <td>2.884934e+07</td>\n",
              "      <td>2.884934e+07</td>\n",
              "      <td>2.884934e+07</td>\n",
              "      <td>64.884907</td>\n",
              "      <td>51.644592</td>\n",
              "      <td>64.884907</td>\n",
              "      <td>52.517166</td>\n",
              "      <td>64.884907</td>\n",
              "      <td>54.508205</td>\n",
              "      <td>154.499665</td>\n",
              "      <td>154.499665</td>\n",
              "      <td>154.499665</td>\n",
              "      <td>-9342300.0</td>\n",
              "      <td>0.018849</td>\n",
              "      <td>0.011227</td>\n",
              "      <td>0.033014</td>\n",
              "      <td>0.065</td>\n",
              "      <td>-0.937</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.083</td>\n",
              "      <td>-1.920000</td>\n",
              "      <td>0.012241</td>\n",
              "      <td>0.002215</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ^vix       wr_5      wr_10  ...  cny=x_change  jpy=x_change  labels\n",
              "1157  13.740000 -49.967445 -34.549546  ...     -0.005256      0.001435     1.0\n",
              "445   16.190001 -91.881121 -91.881121  ...      0.002231      0.006178     2.0\n",
              "458   13.350000 -16.262486 -23.167597  ...     -0.010047     -0.002320     2.0\n",
              "251   22.340000  -0.497524  -0.497524  ...      0.000244      0.006744     0.0\n",
              "1252  16.049999 -35.115093 -35.115093  ...      0.012241      0.002215     1.0\n",
              "\n",
              "[5 rows x 74 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyB_Wb9Fav0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('labels')\n",
        "test_labels = test_dataset.pop('labels')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YumkgVabeud9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ed9a71cc-1e1b-4591-9c4a-42c0e6bbe9ce"
      },
      "source": [
        "train_labels.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1157    1.0\n",
              "445     2.0\n",
              "458     2.0\n",
              "251     0.0\n",
              "1252    1.0\n",
              "Name: labels, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQpxY8Kjeh9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import compute_class_weight\n",
        "def get_sample_weights(y):\n",
        "      y = y.astype(int)  # compute_class_weight needs int labels\n",
        "      class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
        "\n",
        "      print(\"real class weights are {}\".format(class_weights), np.unique(y))\n",
        "      print(\"value_counts\", np.unique(y, return_counts=True))\n",
        "      sample_weights = y.copy().astype(float)\n",
        "      for i in np.unique(y):\n",
        "          sample_weights[sample_weights == i] = class_weights[i]  # if i == 2 else 0.8 * class_weights[i]\n",
        "            # sample_weights = np.where(sample_weights == i, class_weights[int(i)], y_)\n",
        "\n",
        "      return sample_weights\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXhEiJnO28kQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "6f993a27-9db0-4240-c46e-4501799d6270"
      },
      "source": [
        "get_sample_weights(train_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "real class weights are [0.85829308 0.71639785 2.27777778] [0 1 2]\n",
            "value_counts (array([0, 1, 2]), array([414, 496, 156]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1157    0.716398\n",
              "445     2.277778\n",
              "458     2.277778\n",
              "251     0.858293\n",
              "1252    0.716398\n",
              "          ...   \n",
              "584     2.277778\n",
              "147     0.716398\n",
              "160     0.716398\n",
              "750     0.858293\n",
              "859     0.716398\n",
              "Name: labels, Length: 1066, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmTtLI6ufD7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fb8af72-1706-4385-d4a0-b8e01cdc1423"
      },
      "source": [
        "SAMPLE_WEIGHT=get_sample_weights(train_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "real class weights are [0.85829308 0.71639785 2.27777778] [0 1 2]\n",
            "value_counts (array([0, 1, 2]), array([414, 496, 156]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft6KC349cvWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMEH1r2ya1UM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZQxTHBAGIJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "516eccc6-4830-4e0c-b5ab-83d20532bda8"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
        "from operator import itemgetter\n",
        "\n",
        "list_features = list(normed_train_data.columns)\n",
        "select_k_best = SelectKBest(f_classif, k=10)\n",
        "select_k_best.fit(normed_train_data, train_labels)\n",
        "selected_features_anova = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
        "\n",
        "selected_features_anova"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('^vix',\n",
              " 'mfi_15',\n",
              " 'ppo',\n",
              " 'cmf_15',\n",
              " 'cmo_15',\n",
              " 'cci_15',\n",
              " 'kdjk_10',\n",
              " 'rsv_15',\n",
              " 'kdjk_15',\n",
              " 'high_minus_low')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoGj_iK6JdDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "c0dfb871-9f71-4214-8da5-bcaf6ac29aa5"
      },
      "source": [
        "select_k_best = SelectKBest(mutual_info_classif, k=10)\n",
        "select_k_best.fit(normed_train_data, train_labels)\n",
        "selected_features_mic = itemgetter(*select_k_best.get_support(indices=True))(list_features)\n",
        "selected_features_mic"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('mfi_10',\n",
              " 'roc_15',\n",
              " 'cmo_5',\n",
              " 'trix_5',\n",
              " 'cci_10',\n",
              " 'cci_15',\n",
              " 'dpo_10',\n",
              " 'kst_15',\n",
              " 'fi_10',\n",
              " 'fi_15')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS_4c6YyMHl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e14ebab9-f330-41ec-b9b8-d7d8b6cbdf78"
      },
      "source": [
        "X_new = SelectKBest(f_classif, k=10).fit_transform(normed_train_data, train_labels)\n",
        "X_new.shape\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y6IeZLPdDbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hidden_dim,dropout=0.4):\n",
        "    ## input layer\n",
        "    inputs=tf.keras.Input(shape=(X_new.shape[1],))\n",
        "\n",
        "\n",
        "    h1= tf.keras.layers.Dense(units=hidden_dim,activation='relu')(inputs)\n",
        "    h2= tf.keras.layers.Dropout(dropout)(h1)\n",
        "    h3= tf.keras.layers.Dense(units=hidden_dim*2,activation='relu')(h2)\n",
        "    h4= tf.keras.layers.Dropout(dropout)(h3)\n",
        "    h5= tf.keras.layers.Dense(units=hidden_dim*2,activation='relu')(h4)\n",
        "    h6= tf.keras.layers.Dropout(dropout)(h5)\n",
        "    h7= tf.keras.layers.Dense(units=hidden_dim,activation='relu')(h6)\n",
        "\n",
        "    ##output\n",
        "    outputs=tf.keras.layers.Dense(units=3,activation='softmax')(h7)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvYU19fefqf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model = build_model(hidden_dim=64)\n",
        "\n",
        "model.compile(optimizer=optimizer,loss=criterion,metrics=['accuracy'])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RjdYWf5gX4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "5f5d4a13-b3b1-4243-a4b4-c27d55246712"
      },
      "source": [
        "example_batch = X_new[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3311944 , 0.35434002, 0.31446558],\n",
              "       [0.31916222, 0.34007797, 0.34075978],\n",
              "       [0.34260046, 0.32366696, 0.33373263],\n",
              "       [0.38656625, 0.27579185, 0.3376419 ],\n",
              "       [0.33449885, 0.33141133, 0.33408988],\n",
              "       [0.3472859 , 0.32995555, 0.32275853],\n",
              "       [0.3371171 , 0.33598062, 0.32690224],\n",
              "       [0.33492658, 0.3641351 , 0.3009383 ],\n",
              "       [0.36553568, 0.2540086 , 0.38045576],\n",
              "       [0.32678768, 0.3375403 , 0.33567202]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsZt86Vg9Fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42ac8b5a-1445-4abe-9bd4-06721e299877"
      },
      "source": [
        "EPOCHS=1000\n",
        "BATCH_SIZE=120\n",
        "\n",
        "history = model.fit(\n",
        "  X_new, train_labels,\n",
        "  epochs=EPOCHS, batch_size=BATCH_SIZE ,sample_weight=SAMPLE_WEIGHT,validation_split = 0.2, verbose=1,\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 1.1604 - accuracy: 0.3417\n",
            "Epoch: 0, accuracy:0.3791,  loss:1.1280,  val_accuracy:0.4346,  val_loss:1.1072,  \n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1280 - accuracy: 0.3791 - val_loss: 1.1072 - val_accuracy: 0.4346\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.1061 - accuracy: 0.4108 - val_loss: 1.0994 - val_accuracy: 0.3785\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0802 - accuracy: 0.3850 - val_loss: 1.0962 - val_accuracy: 0.3318\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.1118 - accuracy: 0.3509 - val_loss: 1.0929 - val_accuracy: 0.3411\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0837 - accuracy: 0.4061 - val_loss: 1.0912 - val_accuracy: 0.3224\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0955 - accuracy: 0.3627 - val_loss: 1.0904 - val_accuracy: 0.3224\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.1019 - accuracy: 0.3603 - val_loss: 1.0903 - val_accuracy: 0.3131\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.1031 - accuracy: 0.3568 - val_loss: 1.0911 - val_accuracy: 0.3224\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0921 - accuracy: 0.3650 - val_loss: 1.0912 - val_accuracy: 0.3084\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0940 - accuracy: 0.3157 - val_loss: 1.0930 - val_accuracy: 0.3037\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0887 - accuracy: 0.3462 - val_loss: 1.0937 - val_accuracy: 0.2991\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0884 - accuracy: 0.3099 - val_loss: 1.0938 - val_accuracy: 0.2710\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0940 - accuracy: 0.3110 - val_loss: 1.0929 - val_accuracy: 0.2664\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0925 - accuracy: 0.3005 - val_loss: 1.0929 - val_accuracy: 0.2897\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0856 - accuracy: 0.3263 - val_loss: 1.0907 - val_accuracy: 0.2944\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0883 - accuracy: 0.3322 - val_loss: 1.0886 - val_accuracy: 0.2757\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0835 - accuracy: 0.3228 - val_loss: 1.0867 - val_accuracy: 0.2710\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0774 - accuracy: 0.3498 - val_loss: 1.0845 - val_accuracy: 0.3037\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0882 - accuracy: 0.3404 - val_loss: 1.0849 - val_accuracy: 0.3084\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0807 - accuracy: 0.3263 - val_loss: 1.0840 - val_accuracy: 0.3131\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0788 - accuracy: 0.3462 - val_loss: 1.0847 - val_accuracy: 0.3037\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0796 - accuracy: 0.3803 - val_loss: 1.0849 - val_accuracy: 0.3224\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0823 - accuracy: 0.3404 - val_loss: 1.0867 - val_accuracy: 0.3084\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0781 - accuracy: 0.3392 - val_loss: 1.0878 - val_accuracy: 0.3084\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0785 - accuracy: 0.3333 - val_loss: 1.0875 - val_accuracy: 0.2757\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0843 - accuracy: 0.3310 - val_loss: 1.0877 - val_accuracy: 0.2991\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0843 - accuracy: 0.3392 - val_loss: 1.0879 - val_accuracy: 0.3364\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0720 - accuracy: 0.3803 - val_loss: 1.0880 - val_accuracy: 0.3364\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0712 - accuracy: 0.4120 - val_loss: 1.0872 - val_accuracy: 0.3411\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0932 - accuracy: 0.3779 - val_loss: 1.0867 - val_accuracy: 0.3318\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0744 - accuracy: 0.3732 - val_loss: 1.0866 - val_accuracy: 0.2897\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0825 - accuracy: 0.3239 - val_loss: 1.0874 - val_accuracy: 0.2804\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0800 - accuracy: 0.3380 - val_loss: 1.0865 - val_accuracy: 0.3037\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0882 - accuracy: 0.3192 - val_loss: 1.0857 - val_accuracy: 0.2991\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0797 - accuracy: 0.3392 - val_loss: 1.0852 - val_accuracy: 0.3037\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0726 - accuracy: 0.3650 - val_loss: 1.0843 - val_accuracy: 0.3037\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0701 - accuracy: 0.3885 - val_loss: 1.0842 - val_accuracy: 0.3084\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0726 - accuracy: 0.3592 - val_loss: 1.0854 - val_accuracy: 0.2991\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0738 - accuracy: 0.3533 - val_loss: 1.0861 - val_accuracy: 0.3224\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0864 - accuracy: 0.3333 - val_loss: 1.0863 - val_accuracy: 0.3131\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0743 - accuracy: 0.3592 - val_loss: 1.0872 - val_accuracy: 0.2991\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0652 - accuracy: 0.3697 - val_loss: 1.0872 - val_accuracy: 0.2850\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0768 - accuracy: 0.3310 - val_loss: 1.0872 - val_accuracy: 0.2897\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0735 - accuracy: 0.3556 - val_loss: 1.0876 - val_accuracy: 0.2757\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0731 - accuracy: 0.3521 - val_loss: 1.0884 - val_accuracy: 0.2897\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0672 - accuracy: 0.3369 - val_loss: 1.0868 - val_accuracy: 0.2944\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0777 - accuracy: 0.3615 - val_loss: 1.0858 - val_accuracy: 0.3271\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0764 - accuracy: 0.3815 - val_loss: 1.0850 - val_accuracy: 0.3178\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0680 - accuracy: 0.3944 - val_loss: 1.0843 - val_accuracy: 0.3084\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0761 - accuracy: 0.3697 - val_loss: 1.0833 - val_accuracy: 0.3084\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0721 - accuracy: 0.3838 - val_loss: 1.0840 - val_accuracy: 0.3037\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0729 - accuracy: 0.3791 - val_loss: 1.0845 - val_accuracy: 0.3131\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0727 - accuracy: 0.3521 - val_loss: 1.0849 - val_accuracy: 0.2897\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0651 - accuracy: 0.3486 - val_loss: 1.0834 - val_accuracy: 0.2804\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0750 - accuracy: 0.3627 - val_loss: 1.0824 - val_accuracy: 0.3037\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0729 - accuracy: 0.3803 - val_loss: 1.0834 - val_accuracy: 0.2944\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0706 - accuracy: 0.3638 - val_loss: 1.0839 - val_accuracy: 0.2897\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0696 - accuracy: 0.3662 - val_loss: 1.0840 - val_accuracy: 0.2897\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0616 - accuracy: 0.3803 - val_loss: 1.0835 - val_accuracy: 0.3131\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0755 - accuracy: 0.3638 - val_loss: 1.0844 - val_accuracy: 0.3084\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0838 - accuracy: 0.3533 - val_loss: 1.0864 - val_accuracy: 0.3131\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0787 - accuracy: 0.3509 - val_loss: 1.0898 - val_accuracy: 0.2897\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0749 - accuracy: 0.3451 - val_loss: 1.0908 - val_accuracy: 0.2664\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0676 - accuracy: 0.3627 - val_loss: 1.0898 - val_accuracy: 0.2804\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0750 - accuracy: 0.3474 - val_loss: 1.0886 - val_accuracy: 0.2850\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0753 - accuracy: 0.3979 - val_loss: 1.0869 - val_accuracy: 0.3224\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0679 - accuracy: 0.4155 - val_loss: 1.0853 - val_accuracy: 0.3271\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0620 - accuracy: 0.3955 - val_loss: 1.0854 - val_accuracy: 0.3178\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0808 - accuracy: 0.3850 - val_loss: 1.0870 - val_accuracy: 0.3131\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0611 - accuracy: 0.3991 - val_loss: 1.0888 - val_accuracy: 0.2850\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0629 - accuracy: 0.3791 - val_loss: 1.0888 - val_accuracy: 0.2897\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0663 - accuracy: 0.3638 - val_loss: 1.0891 - val_accuracy: 0.3271\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0678 - accuracy: 0.3779 - val_loss: 1.0874 - val_accuracy: 0.2897\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0646 - accuracy: 0.3662 - val_loss: 1.0848 - val_accuracy: 0.2991\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0739 - accuracy: 0.3521 - val_loss: 1.0847 - val_accuracy: 0.2850\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0693 - accuracy: 0.3545 - val_loss: 1.0847 - val_accuracy: 0.2850\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0710 - accuracy: 0.3638 - val_loss: 1.0861 - val_accuracy: 0.2850\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0702 - accuracy: 0.3486 - val_loss: 1.0882 - val_accuracy: 0.2850\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.0609 - accuracy: 0.3791 - val_loss: 1.0894 - val_accuracy: 0.2944\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0570 - accuracy: 0.3932 - val_loss: 1.0905 - val_accuracy: 0.3271\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0753 - accuracy: 0.3908 - val_loss: 1.0913 - val_accuracy: 0.3224\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0664 - accuracy: 0.3826 - val_loss: 1.0908 - val_accuracy: 0.2944\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0536 - accuracy: 0.3826 - val_loss: 1.0912 - val_accuracy: 0.2804\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0639 - accuracy: 0.3697 - val_loss: 1.0908 - val_accuracy: 0.2570\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0539 - accuracy: 0.3556 - val_loss: 1.0888 - val_accuracy: 0.2897\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0617 - accuracy: 0.3439 - val_loss: 1.0879 - val_accuracy: 0.3037\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0644 - accuracy: 0.3427 - val_loss: 1.0899 - val_accuracy: 0.2991\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0626 - accuracy: 0.3615 - val_loss: 1.0895 - val_accuracy: 0.2991\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0718 - accuracy: 0.3826 - val_loss: 1.0903 - val_accuracy: 0.3131\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0609 - accuracy: 0.3932 - val_loss: 1.0906 - val_accuracy: 0.3131\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0641 - accuracy: 0.3862 - val_loss: 1.0911 - val_accuracy: 0.2897\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0580 - accuracy: 0.3862 - val_loss: 1.0924 - val_accuracy: 0.3037\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0523 - accuracy: 0.3556 - val_loss: 1.0927 - val_accuracy: 0.3037\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0600 - accuracy: 0.3615 - val_loss: 1.0931 - val_accuracy: 0.2991\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0542 - accuracy: 0.3955 - val_loss: 1.0914 - val_accuracy: 0.3084\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0617 - accuracy: 0.3627 - val_loss: 1.0895 - val_accuracy: 0.3131\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0591 - accuracy: 0.3815 - val_loss: 1.0896 - val_accuracy: 0.2991\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0570 - accuracy: 0.4014 - val_loss: 1.0904 - val_accuracy: 0.3131\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0551 - accuracy: 0.3908 - val_loss: 1.0903 - val_accuracy: 0.3178\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0514 - accuracy: 0.3709 - val_loss: 1.0877 - val_accuracy: 0.3084\n",
            "Epoch 101/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 1.0876 - accuracy: 0.3083\n",
            "Epoch: 100, accuracy:0.3627,  loss:1.0549,  val_accuracy:0.3178,  val_loss:1.0876,  \n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0549 - accuracy: 0.3627 - val_loss: 1.0876 - val_accuracy: 0.3178\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0509 - accuracy: 0.3732 - val_loss: 1.0892 - val_accuracy: 0.3224\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0684 - accuracy: 0.4096 - val_loss: 1.0902 - val_accuracy: 0.3598\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0617 - accuracy: 0.3850 - val_loss: 1.0903 - val_accuracy: 0.3505\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0619 - accuracy: 0.4038 - val_loss: 1.0909 - val_accuracy: 0.3271\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0540 - accuracy: 0.3850 - val_loss: 1.0921 - val_accuracy: 0.3037\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0542 - accuracy: 0.3732 - val_loss: 1.0914 - val_accuracy: 0.2897\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0623 - accuracy: 0.3662 - val_loss: 1.0908 - val_accuracy: 0.3224\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0468 - accuracy: 0.4190 - val_loss: 1.0914 - val_accuracy: 0.3551\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0676 - accuracy: 0.4190 - val_loss: 1.0912 - val_accuracy: 0.3692\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0561 - accuracy: 0.4354 - val_loss: 1.0910 - val_accuracy: 0.3598\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0574 - accuracy: 0.4237 - val_loss: 1.0910 - val_accuracy: 0.3598\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0607 - accuracy: 0.4155 - val_loss: 1.0922 - val_accuracy: 0.3598\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0529 - accuracy: 0.4237 - val_loss: 1.0915 - val_accuracy: 0.3505\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0598 - accuracy: 0.4026 - val_loss: 1.0894 - val_accuracy: 0.2944\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0503 - accuracy: 0.3944 - val_loss: 1.0900 - val_accuracy: 0.2991\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0460 - accuracy: 0.3838 - val_loss: 1.0902 - val_accuracy: 0.2944\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0463 - accuracy: 0.3850 - val_loss: 1.0906 - val_accuracy: 0.3037\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0584 - accuracy: 0.4038 - val_loss: 1.0907 - val_accuracy: 0.3084\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0567 - accuracy: 0.4437 - val_loss: 1.0896 - val_accuracy: 0.3037\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0537 - accuracy: 0.4366 - val_loss: 1.0896 - val_accuracy: 0.3178\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0538 - accuracy: 0.4425 - val_loss: 1.0898 - val_accuracy: 0.3037\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0481 - accuracy: 0.4155 - val_loss: 1.0902 - val_accuracy: 0.3084\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0474 - accuracy: 0.4202 - val_loss: 1.0932 - val_accuracy: 0.3224\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0492 - accuracy: 0.4214 - val_loss: 1.0953 - val_accuracy: 0.2897\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0553 - accuracy: 0.3897 - val_loss: 1.0970 - val_accuracy: 0.2850\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0524 - accuracy: 0.3838 - val_loss: 1.0958 - val_accuracy: 0.2897\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0451 - accuracy: 0.3779 - val_loss: 1.0917 - val_accuracy: 0.2897\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0501 - accuracy: 0.3815 - val_loss: 1.0918 - val_accuracy: 0.2850\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0397 - accuracy: 0.3955 - val_loss: 1.0936 - val_accuracy: 0.3037\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0404 - accuracy: 0.4061 - val_loss: 1.0927 - val_accuracy: 0.3131\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0403 - accuracy: 0.4237 - val_loss: 1.0865 - val_accuracy: 0.3271\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0428 - accuracy: 0.4120 - val_loss: 1.0831 - val_accuracy: 0.3224\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0345 - accuracy: 0.4085 - val_loss: 1.0838 - val_accuracy: 0.3131\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0678 - accuracy: 0.4085 - val_loss: 1.0823 - val_accuracy: 0.3178\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0540 - accuracy: 0.3756 - val_loss: 1.0843 - val_accuracy: 0.2664\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0419 - accuracy: 0.3638 - val_loss: 1.0849 - val_accuracy: 0.2850\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0467 - accuracy: 0.4143 - val_loss: 1.0832 - val_accuracy: 0.3178\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0483 - accuracy: 0.4178 - val_loss: 1.0809 - val_accuracy: 0.2991\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0387 - accuracy: 0.3944 - val_loss: 1.0791 - val_accuracy: 0.3084\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0393 - accuracy: 0.3932 - val_loss: 1.0763 - val_accuracy: 0.3318\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0458 - accuracy: 0.3979 - val_loss: 1.0764 - val_accuracy: 0.3131\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0392 - accuracy: 0.4061 - val_loss: 1.0786 - val_accuracy: 0.3037\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0246 - accuracy: 0.4085 - val_loss: 1.0790 - val_accuracy: 0.3037\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0371 - accuracy: 0.3991 - val_loss: 1.0773 - val_accuracy: 0.3178\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0403 - accuracy: 0.4143 - val_loss: 1.0781 - val_accuracy: 0.3411\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0508 - accuracy: 0.4049 - val_loss: 1.0786 - val_accuracy: 0.3271\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0289 - accuracy: 0.3744 - val_loss: 1.0814 - val_accuracy: 0.3084\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0283 - accuracy: 0.4460 - val_loss: 1.0829 - val_accuracy: 0.3458\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0500 - accuracy: 0.4554 - val_loss: 1.0814 - val_accuracy: 0.3551\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0245 - accuracy: 0.4519 - val_loss: 1.0777 - val_accuracy: 0.3178\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0302 - accuracy: 0.4049 - val_loss: 1.0780 - val_accuracy: 0.3364\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0506 - accuracy: 0.3451 - val_loss: 1.0814 - val_accuracy: 0.3131\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0433 - accuracy: 0.3862 - val_loss: 1.0874 - val_accuracy: 0.3458\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0338 - accuracy: 0.4108 - val_loss: 1.0914 - val_accuracy: 0.3224\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0299 - accuracy: 0.3944 - val_loss: 1.0885 - val_accuracy: 0.3364\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0297 - accuracy: 0.4108 - val_loss: 1.0811 - val_accuracy: 0.3271\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0348 - accuracy: 0.3955 - val_loss: 1.0790 - val_accuracy: 0.3318\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0305 - accuracy: 0.4096 - val_loss: 1.0782 - val_accuracy: 0.3318\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0223 - accuracy: 0.4143 - val_loss: 1.0798 - val_accuracy: 0.3458\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0385 - accuracy: 0.3838 - val_loss: 1.0800 - val_accuracy: 0.3551\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0390 - accuracy: 0.4096 - val_loss: 1.0793 - val_accuracy: 0.3411\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0261 - accuracy: 0.4178 - val_loss: 1.0806 - val_accuracy: 0.3178\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0247 - accuracy: 0.4237 - val_loss: 1.0744 - val_accuracy: 0.3131\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0405 - accuracy: 0.4214 - val_loss: 1.0714 - val_accuracy: 0.3318\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0428 - accuracy: 0.3838 - val_loss: 1.0728 - val_accuracy: 0.3224\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0280 - accuracy: 0.4390 - val_loss: 1.0742 - val_accuracy: 0.3318\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0386 - accuracy: 0.4108 - val_loss: 1.0747 - val_accuracy: 0.3458\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0260 - accuracy: 0.4261 - val_loss: 1.0745 - val_accuracy: 0.3551\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0281 - accuracy: 0.4155 - val_loss: 1.0735 - val_accuracy: 0.3364\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0300 - accuracy: 0.4413 - val_loss: 1.0744 - val_accuracy: 0.3364\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0485 - accuracy: 0.4237 - val_loss: 1.0751 - val_accuracy: 0.3271\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0243 - accuracy: 0.4120 - val_loss: 1.0761 - val_accuracy: 0.3318\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0400 - accuracy: 0.4178 - val_loss: 1.0820 - val_accuracy: 0.3271\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.0275 - accuracy: 0.4507 - val_loss: 1.0834 - val_accuracy: 0.3364\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0274 - accuracy: 0.4519 - val_loss: 1.0793 - val_accuracy: 0.3551\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0285 - accuracy: 0.4472 - val_loss: 1.0788 - val_accuracy: 0.3178\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0227 - accuracy: 0.4155 - val_loss: 1.0777 - val_accuracy: 0.3505\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0241 - accuracy: 0.4214 - val_loss: 1.0774 - val_accuracy: 0.3458\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0279 - accuracy: 0.4061 - val_loss: 1.0712 - val_accuracy: 0.3458\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0137 - accuracy: 0.4225 - val_loss: 1.0728 - val_accuracy: 0.3364\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0279 - accuracy: 0.4484 - val_loss: 1.0768 - val_accuracy: 0.3411\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0247 - accuracy: 0.4425 - val_loss: 1.0802 - val_accuracy: 0.3411\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0234 - accuracy: 0.4343 - val_loss: 1.0788 - val_accuracy: 0.3411\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0118 - accuracy: 0.4237 - val_loss: 1.0750 - val_accuracy: 0.3505\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0086 - accuracy: 0.4319 - val_loss: 1.0730 - val_accuracy: 0.3458\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0268 - accuracy: 0.4202 - val_loss: 1.0731 - val_accuracy: 0.3645\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0137 - accuracy: 0.4390 - val_loss: 1.0753 - val_accuracy: 0.3411\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0129 - accuracy: 0.4272 - val_loss: 1.0754 - val_accuracy: 0.3318\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0175 - accuracy: 0.4390 - val_loss: 1.0763 - val_accuracy: 0.3411\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0142 - accuracy: 0.4331 - val_loss: 1.0776 - val_accuracy: 0.3458\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0302 - accuracy: 0.4085 - val_loss: 1.0799 - val_accuracy: 0.3505\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0110 - accuracy: 0.4448 - val_loss: 1.0837 - val_accuracy: 0.3505\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0079 - accuracy: 0.4272 - val_loss: 1.0834 - val_accuracy: 0.3364\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0104 - accuracy: 0.4401 - val_loss: 1.0846 - val_accuracy: 0.3271\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0138 - accuracy: 0.4460 - val_loss: 1.0851 - val_accuracy: 0.3084\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0075 - accuracy: 0.4331 - val_loss: 1.0856 - val_accuracy: 0.3178\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0143 - accuracy: 0.4085 - val_loss: 1.0867 - val_accuracy: 0.3318\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0029 - accuracy: 0.4319 - val_loss: 1.0840 - val_accuracy: 0.3364\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0109 - accuracy: 0.4354 - val_loss: 1.0825 - val_accuracy: 0.3411\n",
            "Epoch 201/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.9708 - accuracy: 0.5500\n",
            "Epoch: 200, accuracy:0.4636,  loss:1.0091,  val_accuracy:0.3645,  val_loss:1.0776,  \n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0091 - accuracy: 0.4636 - val_loss: 1.0776 - val_accuracy: 0.3645\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0202 - accuracy: 0.4401 - val_loss: 1.0814 - val_accuracy: 0.4065\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0257 - accuracy: 0.4460 - val_loss: 1.0751 - val_accuracy: 0.3785\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0148 - accuracy: 0.4401 - val_loss: 1.0713 - val_accuracy: 0.3271\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0147 - accuracy: 0.4143 - val_loss: 1.0722 - val_accuracy: 0.3178\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9898 - accuracy: 0.4519 - val_loss: 1.0736 - val_accuracy: 0.3364\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9925 - accuracy: 0.4683 - val_loss: 1.0757 - val_accuracy: 0.3505\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9909 - accuracy: 0.4378 - val_loss: 1.0774 - val_accuracy: 0.3131\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9956 - accuracy: 0.4401 - val_loss: 1.0766 - val_accuracy: 0.3131\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0102 - accuracy: 0.4343 - val_loss: 1.0786 - val_accuracy: 0.3411\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0028 - accuracy: 0.4519 - val_loss: 1.0820 - val_accuracy: 0.3738\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0141 - accuracy: 0.4167 - val_loss: 1.0824 - val_accuracy: 0.3645\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9908 - accuracy: 0.4484 - val_loss: 1.0824 - val_accuracy: 0.3551\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0232 - accuracy: 0.4319 - val_loss: 1.0821 - val_accuracy: 0.3598\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0032 - accuracy: 0.4331 - val_loss: 1.0870 - val_accuracy: 0.3364\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0020 - accuracy: 0.4507 - val_loss: 1.0929 - val_accuracy: 0.3224\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9865 - accuracy: 0.4437 - val_loss: 1.1012 - val_accuracy: 0.3598\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9903 - accuracy: 0.4707 - val_loss: 1.1065 - val_accuracy: 0.3551\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0011 - accuracy: 0.4648 - val_loss: 1.1055 - val_accuracy: 0.3551\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0053 - accuracy: 0.4495 - val_loss: 1.1044 - val_accuracy: 0.3458\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0035 - accuracy: 0.4425 - val_loss: 1.1040 - val_accuracy: 0.3505\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9871 - accuracy: 0.4425 - val_loss: 1.1001 - val_accuracy: 0.3505\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0027 - accuracy: 0.4613 - val_loss: 1.0973 - val_accuracy: 0.3598\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0045 - accuracy: 0.4038 - val_loss: 1.0903 - val_accuracy: 0.3458\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9909 - accuracy: 0.4331 - val_loss: 1.0881 - val_accuracy: 0.3551\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0046 - accuracy: 0.4319 - val_loss: 1.0870 - val_accuracy: 0.3785\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9943 - accuracy: 0.4296 - val_loss: 1.0887 - val_accuracy: 0.3785\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9898 - accuracy: 0.4707 - val_loss: 1.0882 - val_accuracy: 0.3785\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9878 - accuracy: 0.4707 - val_loss: 1.0936 - val_accuracy: 0.3645\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9920 - accuracy: 0.4308 - val_loss: 1.0993 - val_accuracy: 0.3364\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0107 - accuracy: 0.4308 - val_loss: 1.1016 - val_accuracy: 0.3364\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0061 - accuracy: 0.4237 - val_loss: 1.1010 - val_accuracy: 0.3224\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0013 - accuracy: 0.4366 - val_loss: 1.0963 - val_accuracy: 0.3645\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9699 - accuracy: 0.4683 - val_loss: 1.0899 - val_accuracy: 0.3458\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0091 - accuracy: 0.4413 - val_loss: 1.0883 - val_accuracy: 0.3458\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9999 - accuracy: 0.4425 - val_loss: 1.0883 - val_accuracy: 0.3505\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9888 - accuracy: 0.4225 - val_loss: 1.0840 - val_accuracy: 0.3458\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9794 - accuracy: 0.4366 - val_loss: 1.0781 - val_accuracy: 0.3738\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9795 - accuracy: 0.4531 - val_loss: 1.0792 - val_accuracy: 0.3598\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0100 - accuracy: 0.4237 - val_loss: 1.0787 - val_accuracy: 0.3505\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0068 - accuracy: 0.4284 - val_loss: 1.0798 - val_accuracy: 0.3738\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9866 - accuracy: 0.4366 - val_loss: 1.0859 - val_accuracy: 0.3598\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9888 - accuracy: 0.4190 - val_loss: 1.0842 - val_accuracy: 0.3692\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9936 - accuracy: 0.4272 - val_loss: 1.0852 - val_accuracy: 0.3879\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9984 - accuracy: 0.4214 - val_loss: 1.0818 - val_accuracy: 0.3738\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9913 - accuracy: 0.4343 - val_loss: 1.0865 - val_accuracy: 0.3738\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9849 - accuracy: 0.4519 - val_loss: 1.0877 - val_accuracy: 0.3692\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9807 - accuracy: 0.4683 - val_loss: 1.0817 - val_accuracy: 0.3458\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0107 - accuracy: 0.4284 - val_loss: 1.0795 - val_accuracy: 0.3785\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9712 - accuracy: 0.4718 - val_loss: 1.0788 - val_accuracy: 0.3738\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9755 - accuracy: 0.4765 - val_loss: 1.0789 - val_accuracy: 0.3598\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9810 - accuracy: 0.4542 - val_loss: 1.0819 - val_accuracy: 0.3458\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9763 - accuracy: 0.4601 - val_loss: 1.0857 - val_accuracy: 0.3458\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0016 - accuracy: 0.4366 - val_loss: 1.0916 - val_accuracy: 0.3411\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9926 - accuracy: 0.4531 - val_loss: 1.0938 - val_accuracy: 0.3645\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9988 - accuracy: 0.4484 - val_loss: 1.0932 - val_accuracy: 0.3785\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9723 - accuracy: 0.4718 - val_loss: 1.0884 - val_accuracy: 0.3785\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9801 - accuracy: 0.4624 - val_loss: 1.0853 - val_accuracy: 0.3692\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9713 - accuracy: 0.4742 - val_loss: 1.0918 - val_accuracy: 0.3738\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9914 - accuracy: 0.4718 - val_loss: 1.0843 - val_accuracy: 0.3925\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9981 - accuracy: 0.4601 - val_loss: 1.0796 - val_accuracy: 0.3738\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9965 - accuracy: 0.4354 - val_loss: 1.0800 - val_accuracy: 0.3551\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9956 - accuracy: 0.4636 - val_loss: 1.0795 - val_accuracy: 0.3598\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9791 - accuracy: 0.4624 - val_loss: 1.0860 - val_accuracy: 0.3551\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9734 - accuracy: 0.4742 - val_loss: 1.0994 - val_accuracy: 0.3738\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9678 - accuracy: 0.4671 - val_loss: 1.0917 - val_accuracy: 0.3645\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9645 - accuracy: 0.4859 - val_loss: 1.0790 - val_accuracy: 0.3879\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9799 - accuracy: 0.4542 - val_loss: 1.0769 - val_accuracy: 0.3832\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9845 - accuracy: 0.4707 - val_loss: 1.0806 - val_accuracy: 0.3925\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9777 - accuracy: 0.4836 - val_loss: 1.0846 - val_accuracy: 0.3972\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9720 - accuracy: 0.4519 - val_loss: 1.0880 - val_accuracy: 0.4065\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.9682 - accuracy: 0.4824 - val_loss: 1.0931 - val_accuracy: 0.3879\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9615 - accuracy: 0.4495 - val_loss: 1.0946 - val_accuracy: 0.3738\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9544 - accuracy: 0.4777 - val_loss: 1.1031 - val_accuracy: 0.3645\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9770 - accuracy: 0.4495 - val_loss: 1.1138 - val_accuracy: 0.3879\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9632 - accuracy: 0.4742 - val_loss: 1.1198 - val_accuracy: 0.3692\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9680 - accuracy: 0.4754 - val_loss: 1.1230 - val_accuracy: 0.3738\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9706 - accuracy: 0.4448 - val_loss: 1.1246 - val_accuracy: 0.3925\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9806 - accuracy: 0.4648 - val_loss: 1.1238 - val_accuracy: 0.3972\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9679 - accuracy: 0.5094 - val_loss: 1.1221 - val_accuracy: 0.4065\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.9690 - accuracy: 0.4894 - val_loss: 1.1211 - val_accuracy: 0.3972\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9621 - accuracy: 0.4812 - val_loss: 1.1233 - val_accuracy: 0.4019\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9455 - accuracy: 0.4754 - val_loss: 1.1250 - val_accuracy: 0.3645\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9789 - accuracy: 0.4847 - val_loss: 1.1145 - val_accuracy: 0.3364\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.0050 - accuracy: 0.4484 - val_loss: 1.1023 - val_accuracy: 0.3505\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9557 - accuracy: 0.4648 - val_loss: 1.1051 - val_accuracy: 0.3645\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9804 - accuracy: 0.4754 - val_loss: 1.1116 - val_accuracy: 0.3832\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9544 - accuracy: 0.4918 - val_loss: 1.1117 - val_accuracy: 0.3598\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9736 - accuracy: 0.4847 - val_loss: 1.1065 - val_accuracy: 0.3458\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9572 - accuracy: 0.4765 - val_loss: 1.1081 - val_accuracy: 0.3318\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9684 - accuracy: 0.4519 - val_loss: 1.1067 - val_accuracy: 0.3551\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9365 - accuracy: 0.4977 - val_loss: 1.1143 - val_accuracy: 0.3738\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9675 - accuracy: 0.4648 - val_loss: 1.1104 - val_accuracy: 0.3832\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9766 - accuracy: 0.4660 - val_loss: 1.1009 - val_accuracy: 0.3692\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9565 - accuracy: 0.4800 - val_loss: 1.1029 - val_accuracy: 0.3692\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9568 - accuracy: 0.4613 - val_loss: 1.0992 - val_accuracy: 0.3692\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9820 - accuracy: 0.4577 - val_loss: 1.1058 - val_accuracy: 0.3832\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9464 - accuracy: 0.4894 - val_loss: 1.1077 - val_accuracy: 0.3692\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9791 - accuracy: 0.4859 - val_loss: 1.1166 - val_accuracy: 0.3645\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9619 - accuracy: 0.4636 - val_loss: 1.1216 - val_accuracy: 0.3598\n",
            "Epoch 301/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.9775 - accuracy: 0.4333\n",
            "Epoch: 300, accuracy:0.4730,  loss:0.9925,  val_accuracy:0.3551,  val_loss:1.1181,  \n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9925 - accuracy: 0.4730 - val_loss: 1.1181 - val_accuracy: 0.3551\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9782 - accuracy: 0.4613 - val_loss: 1.1149 - val_accuracy: 0.3505\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9606 - accuracy: 0.4883 - val_loss: 1.1133 - val_accuracy: 0.3692\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9290 - accuracy: 0.4930 - val_loss: 1.1150 - val_accuracy: 0.3551\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9463 - accuracy: 0.4812 - val_loss: 1.1141 - val_accuracy: 0.3785\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9385 - accuracy: 0.4930 - val_loss: 1.1158 - val_accuracy: 0.3598\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9336 - accuracy: 0.4883 - val_loss: 1.1268 - val_accuracy: 0.3692\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9381 - accuracy: 0.5188 - val_loss: 1.1235 - val_accuracy: 0.3458\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9437 - accuracy: 0.4718 - val_loss: 1.1216 - val_accuracy: 0.3411\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9600 - accuracy: 0.4777 - val_loss: 1.1185 - val_accuracy: 0.3645\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9684 - accuracy: 0.4648 - val_loss: 1.1170 - val_accuracy: 0.3879\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9748 - accuracy: 0.4754 - val_loss: 1.1264 - val_accuracy: 0.3879\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9178 - accuracy: 0.5000 - val_loss: 1.1369 - val_accuracy: 0.3738\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9424 - accuracy: 0.4918 - val_loss: 1.1353 - val_accuracy: 0.3505\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9501 - accuracy: 0.4707 - val_loss: 1.1277 - val_accuracy: 0.3458\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9485 - accuracy: 0.4660 - val_loss: 1.1223 - val_accuracy: 0.3458\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9516 - accuracy: 0.4836 - val_loss: 1.1232 - val_accuracy: 0.3505\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9371 - accuracy: 0.4965 - val_loss: 1.1169 - val_accuracy: 0.3505\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9401 - accuracy: 0.4800 - val_loss: 1.1151 - val_accuracy: 0.3318\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9596 - accuracy: 0.4918 - val_loss: 1.1217 - val_accuracy: 0.3551\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9467 - accuracy: 0.4718 - val_loss: 1.1193 - val_accuracy: 0.3598\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9435 - accuracy: 0.4507 - val_loss: 1.1137 - val_accuracy: 0.3551\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9509 - accuracy: 0.4671 - val_loss: 1.1194 - val_accuracy: 0.3505\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9591 - accuracy: 0.4871 - val_loss: 1.1245 - val_accuracy: 0.3692\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9620 - accuracy: 0.4824 - val_loss: 1.1256 - val_accuracy: 0.3598\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9521 - accuracy: 0.5106 - val_loss: 1.1257 - val_accuracy: 0.3458\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9457 - accuracy: 0.5106 - val_loss: 1.1216 - val_accuracy: 0.3458\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9638 - accuracy: 0.4777 - val_loss: 1.1288 - val_accuracy: 0.3832\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9489 - accuracy: 0.4977 - val_loss: 1.1330 - val_accuracy: 0.3645\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9530 - accuracy: 0.4965 - val_loss: 1.1339 - val_accuracy: 0.3458\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9279 - accuracy: 0.4777 - val_loss: 1.1365 - val_accuracy: 0.3505\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9698 - accuracy: 0.4577 - val_loss: 1.1319 - val_accuracy: 0.3598\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9497 - accuracy: 0.4765 - val_loss: 1.1324 - val_accuracy: 0.3458\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9509 - accuracy: 0.4742 - val_loss: 1.1290 - val_accuracy: 0.3598\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9608 - accuracy: 0.4765 - val_loss: 1.1223 - val_accuracy: 0.3458\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9470 - accuracy: 0.4765 - val_loss: 1.1242 - val_accuracy: 0.3364\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9573 - accuracy: 0.4308 - val_loss: 1.1279 - val_accuracy: 0.3318\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9514 - accuracy: 0.4824 - val_loss: 1.1259 - val_accuracy: 0.3271\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9617 - accuracy: 0.4718 - val_loss: 1.1282 - val_accuracy: 0.3738\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9447 - accuracy: 0.5000 - val_loss: 1.1304 - val_accuracy: 0.4019\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9373 - accuracy: 0.4812 - val_loss: 1.1243 - val_accuracy: 0.3738\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9451 - accuracy: 0.4871 - val_loss: 1.1324 - val_accuracy: 0.3505\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9425 - accuracy: 0.5023 - val_loss: 1.1312 - val_accuracy: 0.3458\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9431 - accuracy: 0.4859 - val_loss: 1.1271 - val_accuracy: 0.3178\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9175 - accuracy: 0.4812 - val_loss: 1.1343 - val_accuracy: 0.3364\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9551 - accuracy: 0.4871 - val_loss: 1.1368 - val_accuracy: 0.3364\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9218 - accuracy: 0.5070 - val_loss: 1.1399 - val_accuracy: 0.3645\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9378 - accuracy: 0.5047 - val_loss: 1.1420 - val_accuracy: 0.3879\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9203 - accuracy: 0.4871 - val_loss: 1.1514 - val_accuracy: 0.3879\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9353 - accuracy: 0.5153 - val_loss: 1.1553 - val_accuracy: 0.3972\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9679 - accuracy: 0.4871 - val_loss: 1.1515 - val_accuracy: 0.3879\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9571 - accuracy: 0.4718 - val_loss: 1.1544 - val_accuracy: 0.3738\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9825 - accuracy: 0.4836 - val_loss: 1.1564 - val_accuracy: 0.3832\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9087 - accuracy: 0.5129 - val_loss: 1.1466 - val_accuracy: 0.3738\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9051 - accuracy: 0.5094 - val_loss: 1.1455 - val_accuracy: 0.3645\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9498 - accuracy: 0.4742 - val_loss: 1.1483 - val_accuracy: 0.3458\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9266 - accuracy: 0.4930 - val_loss: 1.1487 - val_accuracy: 0.3505\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9411 - accuracy: 0.4883 - val_loss: 1.1520 - val_accuracy: 0.3551\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9442 - accuracy: 0.5047 - val_loss: 1.1406 - val_accuracy: 0.3645\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9242 - accuracy: 0.5070 - val_loss: 1.1352 - val_accuracy: 0.3598\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9058 - accuracy: 0.4930 - val_loss: 1.1298 - val_accuracy: 0.3364\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9248 - accuracy: 0.4941 - val_loss: 1.1309 - val_accuracy: 0.3692\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9063 - accuracy: 0.5023 - val_loss: 1.1353 - val_accuracy: 0.3925\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9439 - accuracy: 0.5164 - val_loss: 1.1403 - val_accuracy: 0.3551\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9254 - accuracy: 0.4988 - val_loss: 1.1432 - val_accuracy: 0.3505\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9052 - accuracy: 0.5035 - val_loss: 1.1491 - val_accuracy: 0.3458\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9269 - accuracy: 0.4977 - val_loss: 1.1644 - val_accuracy: 0.3551\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9147 - accuracy: 0.5035 - val_loss: 1.1678 - val_accuracy: 0.3551\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9311 - accuracy: 0.5106 - val_loss: 1.1619 - val_accuracy: 0.3598\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9497 - accuracy: 0.5141 - val_loss: 1.1504 - val_accuracy: 0.3598\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9044 - accuracy: 0.5235 - val_loss: 1.1413 - val_accuracy: 0.3551\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9118 - accuracy: 0.5106 - val_loss: 1.1395 - val_accuracy: 0.3832\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9323 - accuracy: 0.4977 - val_loss: 1.1374 - val_accuracy: 0.3551\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9320 - accuracy: 0.4977 - val_loss: 1.1358 - val_accuracy: 0.3785\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9256 - accuracy: 0.5070 - val_loss: 1.1210 - val_accuracy: 0.3785\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9143 - accuracy: 0.5000 - val_loss: 1.1221 - val_accuracy: 0.3925\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9111 - accuracy: 0.4871 - val_loss: 1.1364 - val_accuracy: 0.3972\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9193 - accuracy: 0.5082 - val_loss: 1.1561 - val_accuracy: 0.3972\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9009 - accuracy: 0.5293 - val_loss: 1.1618 - val_accuracy: 0.3879\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9270 - accuracy: 0.5164 - val_loss: 1.1505 - val_accuracy: 0.3879\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8950 - accuracy: 0.4941 - val_loss: 1.1337 - val_accuracy: 0.3551\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9168 - accuracy: 0.4977 - val_loss: 1.1401 - val_accuracy: 0.3645\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9011 - accuracy: 0.5106 - val_loss: 1.1420 - val_accuracy: 0.3925\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9176 - accuracy: 0.5129 - val_loss: 1.1552 - val_accuracy: 0.3832\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9198 - accuracy: 0.5047 - val_loss: 1.1632 - val_accuracy: 0.3879\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9291 - accuracy: 0.5340 - val_loss: 1.1685 - val_accuracy: 0.3598\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9037 - accuracy: 0.5012 - val_loss: 1.1732 - val_accuracy: 0.3598\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9096 - accuracy: 0.4906 - val_loss: 1.1859 - val_accuracy: 0.3692\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9440 - accuracy: 0.5094 - val_loss: 1.1882 - val_accuracy: 0.3692\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.9297 - accuracy: 0.5059 - val_loss: 1.1869 - val_accuracy: 0.3785\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9056 - accuracy: 0.4953 - val_loss: 1.1721 - val_accuracy: 0.3692\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9198 - accuracy: 0.5082 - val_loss: 1.1760 - val_accuracy: 0.3411\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9250 - accuracy: 0.4800 - val_loss: 1.1824 - val_accuracy: 0.3551\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9241 - accuracy: 0.4988 - val_loss: 1.1766 - val_accuracy: 0.3505\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9372 - accuracy: 0.5188 - val_loss: 1.1766 - val_accuracy: 0.3551\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9184 - accuracy: 0.5070 - val_loss: 1.1636 - val_accuracy: 0.3364\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9228 - accuracy: 0.4906 - val_loss: 1.1610 - val_accuracy: 0.3271\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9402 - accuracy: 0.4871 - val_loss: 1.1631 - val_accuracy: 0.3271\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9058 - accuracy: 0.5141 - val_loss: 1.1699 - val_accuracy: 0.3692\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8928 - accuracy: 0.5340 - val_loss: 1.1790 - val_accuracy: 0.3879\n",
            "Epoch 401/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.8935 - accuracy: 0.5250\n",
            "Epoch: 400, accuracy:0.4941,  loss:0.9393,  val_accuracy:0.3738,  val_loss:1.1801,  \n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9393 - accuracy: 0.4941 - val_loss: 1.1801 - val_accuracy: 0.3738\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9663 - accuracy: 0.4742 - val_loss: 1.1772 - val_accuracy: 0.3785\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9169 - accuracy: 0.5258 - val_loss: 1.1769 - val_accuracy: 0.3505\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8828 - accuracy: 0.4883 - val_loss: 1.1815 - val_accuracy: 0.3411\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8804 - accuracy: 0.5188 - val_loss: 1.1922 - val_accuracy: 0.3551\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9305 - accuracy: 0.4894 - val_loss: 1.1900 - val_accuracy: 0.3645\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8930 - accuracy: 0.5012 - val_loss: 1.1822 - val_accuracy: 0.3692\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9114 - accuracy: 0.5047 - val_loss: 1.1902 - val_accuracy: 0.3879\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8942 - accuracy: 0.5141 - val_loss: 1.1969 - val_accuracy: 0.3879\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8950 - accuracy: 0.5246 - val_loss: 1.2018 - val_accuracy: 0.3692\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9331 - accuracy: 0.5000 - val_loss: 1.2035 - val_accuracy: 0.3645\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9148 - accuracy: 0.4965 - val_loss: 1.2062 - val_accuracy: 0.3738\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8961 - accuracy: 0.5153 - val_loss: 1.2020 - val_accuracy: 0.3785\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9280 - accuracy: 0.5153 - val_loss: 1.1996 - val_accuracy: 0.3785\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8816 - accuracy: 0.5059 - val_loss: 1.1946 - val_accuracy: 0.3551\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.9041 - accuracy: 0.4883 - val_loss: 1.1886 - val_accuracy: 0.3505\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9449 - accuracy: 0.5059 - val_loss: 1.1908 - val_accuracy: 0.3598\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8943 - accuracy: 0.4894 - val_loss: 1.1925 - val_accuracy: 0.3738\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9192 - accuracy: 0.4847 - val_loss: 1.1912 - val_accuracy: 0.3645\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9118 - accuracy: 0.4894 - val_loss: 1.1805 - val_accuracy: 0.3785\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8953 - accuracy: 0.5117 - val_loss: 1.1784 - val_accuracy: 0.3785\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9278 - accuracy: 0.5047 - val_loss: 1.1642 - val_accuracy: 0.3785\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9305 - accuracy: 0.5023 - val_loss: 1.1597 - val_accuracy: 0.3738\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9033 - accuracy: 0.4988 - val_loss: 1.1596 - val_accuracy: 0.3598\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9273 - accuracy: 0.5082 - val_loss: 1.1571 - val_accuracy: 0.3551\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.9160 - accuracy: 0.4859 - val_loss: 1.1607 - val_accuracy: 0.3505\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8959 - accuracy: 0.5000 - val_loss: 1.1714 - val_accuracy: 0.3692\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9295 - accuracy: 0.5129 - val_loss: 1.1767 - val_accuracy: 0.3692\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8975 - accuracy: 0.5200 - val_loss: 1.1744 - val_accuracy: 0.3598\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8857 - accuracy: 0.5317 - val_loss: 1.1637 - val_accuracy: 0.3505\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8982 - accuracy: 0.5164 - val_loss: 1.1705 - val_accuracy: 0.3692\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8887 - accuracy: 0.5059 - val_loss: 1.1816 - val_accuracy: 0.3879\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8970 - accuracy: 0.5023 - val_loss: 1.1973 - val_accuracy: 0.3458\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8791 - accuracy: 0.5223 - val_loss: 1.2156 - val_accuracy: 0.3832\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8977 - accuracy: 0.5200 - val_loss: 1.2194 - val_accuracy: 0.3505\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8579 - accuracy: 0.5176 - val_loss: 1.2308 - val_accuracy: 0.3645\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8990 - accuracy: 0.5293 - val_loss: 1.2233 - val_accuracy: 0.3318\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8915 - accuracy: 0.5188 - val_loss: 1.2223 - val_accuracy: 0.3645\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8907 - accuracy: 0.5117 - val_loss: 1.2126 - val_accuracy: 0.3598\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9259 - accuracy: 0.5211 - val_loss: 1.1978 - val_accuracy: 0.3692\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8689 - accuracy: 0.5352 - val_loss: 1.2049 - val_accuracy: 0.3645\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9128 - accuracy: 0.5070 - val_loss: 1.2008 - val_accuracy: 0.3785\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9070 - accuracy: 0.5176 - val_loss: 1.1802 - val_accuracy: 0.3692\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8855 - accuracy: 0.5505 - val_loss: 1.1739 - val_accuracy: 0.3505\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9068 - accuracy: 0.5094 - val_loss: 1.1775 - val_accuracy: 0.3785\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8944 - accuracy: 0.5000 - val_loss: 1.1751 - val_accuracy: 0.3692\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8804 - accuracy: 0.4918 - val_loss: 1.1766 - val_accuracy: 0.3645\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8829 - accuracy: 0.5082 - val_loss: 1.1880 - val_accuracy: 0.3598\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9535 - accuracy: 0.4859 - val_loss: 1.1785 - val_accuracy: 0.3738\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8742 - accuracy: 0.5200 - val_loss: 1.1560 - val_accuracy: 0.3925\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8954 - accuracy: 0.5094 - val_loss: 1.1660 - val_accuracy: 0.3785\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.9294 - accuracy: 0.5094 - val_loss: 1.1735 - val_accuracy: 0.3738\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9101 - accuracy: 0.5023 - val_loss: 1.1727 - val_accuracy: 0.3738\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8979 - accuracy: 0.5082 - val_loss: 1.1759 - val_accuracy: 0.3785\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8763 - accuracy: 0.5070 - val_loss: 1.1822 - val_accuracy: 0.3598\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8967 - accuracy: 0.5200 - val_loss: 1.1838 - val_accuracy: 0.3411\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8921 - accuracy: 0.4941 - val_loss: 1.1905 - val_accuracy: 0.3785\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8804 - accuracy: 0.5434 - val_loss: 1.1885 - val_accuracy: 0.3972\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9111 - accuracy: 0.5129 - val_loss: 1.1718 - val_accuracy: 0.3785\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8798 - accuracy: 0.5188 - val_loss: 1.1797 - val_accuracy: 0.3598\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8706 - accuracy: 0.5352 - val_loss: 1.2055 - val_accuracy: 0.3692\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9177 - accuracy: 0.5200 - val_loss: 1.2124 - val_accuracy: 0.3738\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9169 - accuracy: 0.5141 - val_loss: 1.2014 - val_accuracy: 0.3738\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8953 - accuracy: 0.5070 - val_loss: 1.2131 - val_accuracy: 0.3785\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8883 - accuracy: 0.5117 - val_loss: 1.2234 - val_accuracy: 0.3645\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9111 - accuracy: 0.5364 - val_loss: 1.2109 - val_accuracy: 0.3645\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8866 - accuracy: 0.5094 - val_loss: 1.2074 - val_accuracy: 0.3458\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8914 - accuracy: 0.4977 - val_loss: 1.2123 - val_accuracy: 0.3738\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8980 - accuracy: 0.5399 - val_loss: 1.1969 - val_accuracy: 0.3785\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8753 - accuracy: 0.5340 - val_loss: 1.1832 - val_accuracy: 0.3879\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9298 - accuracy: 0.5082 - val_loss: 1.1715 - val_accuracy: 0.3692\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9062 - accuracy: 0.4707 - val_loss: 1.1459 - val_accuracy: 0.3505\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8986 - accuracy: 0.5106 - val_loss: 1.1463 - val_accuracy: 0.3785\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8820 - accuracy: 0.5153 - val_loss: 1.1577 - val_accuracy: 0.3692\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.9064 - accuracy: 0.5376 - val_loss: 1.1622 - val_accuracy: 0.3598\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8721 - accuracy: 0.5376 - val_loss: 1.1707 - val_accuracy: 0.3598\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8845 - accuracy: 0.5246 - val_loss: 1.1826 - val_accuracy: 0.3692\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9185 - accuracy: 0.4918 - val_loss: 1.1915 - val_accuracy: 0.3645\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.9261 - accuracy: 0.5246 - val_loss: 1.1942 - val_accuracy: 0.3598\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8816 - accuracy: 0.5528 - val_loss: 1.1955 - val_accuracy: 0.3551\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8896 - accuracy: 0.5176 - val_loss: 1.2076 - val_accuracy: 0.3551\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8898 - accuracy: 0.4930 - val_loss: 1.2228 - val_accuracy: 0.3505\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8804 - accuracy: 0.4988 - val_loss: 1.2321 - val_accuracy: 0.3692\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8698 - accuracy: 0.5399 - val_loss: 1.2320 - val_accuracy: 0.4019\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8592 - accuracy: 0.5516 - val_loss: 1.2333 - val_accuracy: 0.3879\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8753 - accuracy: 0.5387 - val_loss: 1.2340 - val_accuracy: 0.3925\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8909 - accuracy: 0.5246 - val_loss: 1.2284 - val_accuracy: 0.3832\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8562 - accuracy: 0.5282 - val_loss: 1.2305 - val_accuracy: 0.3832\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8674 - accuracy: 0.5329 - val_loss: 1.2426 - val_accuracy: 0.3738\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8480 - accuracy: 0.5340 - val_loss: 1.2609 - val_accuracy: 0.3785\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9080 - accuracy: 0.5446 - val_loss: 1.2740 - val_accuracy: 0.3551\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8779 - accuracy: 0.5188 - val_loss: 1.2484 - val_accuracy: 0.3785\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8710 - accuracy: 0.5176 - val_loss: 1.2311 - val_accuracy: 0.3832\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8899 - accuracy: 0.5235 - val_loss: 1.2238 - val_accuracy: 0.3738\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8534 - accuracy: 0.5516 - val_loss: 1.2324 - val_accuracy: 0.3692\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8727 - accuracy: 0.5493 - val_loss: 1.2577 - val_accuracy: 0.3738\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8928 - accuracy: 0.5129 - val_loss: 1.2563 - val_accuracy: 0.3832\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8841 - accuracy: 0.5458 - val_loss: 1.2236 - val_accuracy: 0.3598\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8573 - accuracy: 0.5246 - val_loss: 1.2223 - val_accuracy: 0.3738\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8689 - accuracy: 0.5164 - val_loss: 1.2420 - val_accuracy: 0.3738\n",
            "Epoch 501/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.7581 - accuracy: 0.6750\n",
            "Epoch: 500, accuracy:0.5200,  loss:0.8664,  val_accuracy:0.3738,  val_loss:1.2479,  \n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8664 - accuracy: 0.5200 - val_loss: 1.2479 - val_accuracy: 0.3738\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8672 - accuracy: 0.5493 - val_loss: 1.2188 - val_accuracy: 0.3925\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8891 - accuracy: 0.5270 - val_loss: 1.2139 - val_accuracy: 0.3692\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9036 - accuracy: 0.5282 - val_loss: 1.2189 - val_accuracy: 0.3645\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8756 - accuracy: 0.5059 - val_loss: 1.2293 - val_accuracy: 0.3738\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8883 - accuracy: 0.5446 - val_loss: 1.2416 - val_accuracy: 0.3832\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8808 - accuracy: 0.5282 - val_loss: 1.2356 - val_accuracy: 0.3692\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8895 - accuracy: 0.5376 - val_loss: 1.2111 - val_accuracy: 0.3785\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8783 - accuracy: 0.5106 - val_loss: 1.1965 - val_accuracy: 0.3738\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8664 - accuracy: 0.5376 - val_loss: 1.1913 - val_accuracy: 0.3738\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8996 - accuracy: 0.4977 - val_loss: 1.1932 - val_accuracy: 0.3785\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8937 - accuracy: 0.5293 - val_loss: 1.1920 - val_accuracy: 0.3832\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8614 - accuracy: 0.5340 - val_loss: 1.1958 - val_accuracy: 0.3832\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8979 - accuracy: 0.5141 - val_loss: 1.1984 - val_accuracy: 0.3972\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8954 - accuracy: 0.5270 - val_loss: 1.1892 - val_accuracy: 0.3692\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8528 - accuracy: 0.5270 - val_loss: 1.1943 - val_accuracy: 0.3785\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8536 - accuracy: 0.5505 - val_loss: 1.2137 - val_accuracy: 0.3879\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8867 - accuracy: 0.5211 - val_loss: 1.2129 - val_accuracy: 0.3879\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8560 - accuracy: 0.5293 - val_loss: 1.2155 - val_accuracy: 0.4112\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8846 - accuracy: 0.5164 - val_loss: 1.2246 - val_accuracy: 0.4112\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8374 - accuracy: 0.5716 - val_loss: 1.2297 - val_accuracy: 0.4065\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8623 - accuracy: 0.5235 - val_loss: 1.2478 - val_accuracy: 0.3879\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8912 - accuracy: 0.5293 - val_loss: 1.2626 - val_accuracy: 0.3551\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.9514 - accuracy: 0.5176 - val_loss: 1.2473 - val_accuracy: 0.3598\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8514 - accuracy: 0.5599 - val_loss: 1.2200 - val_accuracy: 0.3411\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.9052 - accuracy: 0.4918 - val_loss: 1.2226 - val_accuracy: 0.3598\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8813 - accuracy: 0.5153 - val_loss: 1.2274 - val_accuracy: 0.3178\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8794 - accuracy: 0.5141 - val_loss: 1.2427 - val_accuracy: 0.3318\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8711 - accuracy: 0.5012 - val_loss: 1.2511 - val_accuracy: 0.3178\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8254 - accuracy: 0.5423 - val_loss: 1.2678 - val_accuracy: 0.3879\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8604 - accuracy: 0.5235 - val_loss: 1.2815 - val_accuracy: 0.3692\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8617 - accuracy: 0.5563 - val_loss: 1.2685 - val_accuracy: 0.3785\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8655 - accuracy: 0.5376 - val_loss: 1.2658 - val_accuracy: 0.3505\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8470 - accuracy: 0.5399 - val_loss: 1.2690 - val_accuracy: 0.3645\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8690 - accuracy: 0.5211 - val_loss: 1.2721 - val_accuracy: 0.3645\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8952 - accuracy: 0.5329 - val_loss: 1.2552 - val_accuracy: 0.3785\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8750 - accuracy: 0.5211 - val_loss: 1.2276 - val_accuracy: 0.3692\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8547 - accuracy: 0.5434 - val_loss: 1.2350 - val_accuracy: 0.3879\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8650 - accuracy: 0.5211 - val_loss: 1.2385 - val_accuracy: 0.3645\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8964 - accuracy: 0.5235 - val_loss: 1.2275 - val_accuracy: 0.3598\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8653 - accuracy: 0.5106 - val_loss: 1.2306 - val_accuracy: 0.3645\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8557 - accuracy: 0.5164 - val_loss: 1.2365 - val_accuracy: 0.3972\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8706 - accuracy: 0.5376 - val_loss: 1.2396 - val_accuracy: 0.3972\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8783 - accuracy: 0.5411 - val_loss: 1.2503 - val_accuracy: 0.3832\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.8690 - accuracy: 0.5493 - val_loss: 1.2497 - val_accuracy: 0.3738\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8629 - accuracy: 0.5340 - val_loss: 1.2333 - val_accuracy: 0.3551\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8488 - accuracy: 0.5305 - val_loss: 1.2398 - val_accuracy: 0.3692\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8090 - accuracy: 0.5411 - val_loss: 1.2318 - val_accuracy: 0.3925\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8258 - accuracy: 0.5763 - val_loss: 1.2376 - val_accuracy: 0.3879\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8309 - accuracy: 0.5493 - val_loss: 1.2447 - val_accuracy: 0.3692\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8423 - accuracy: 0.5716 - val_loss: 1.2582 - val_accuracy: 0.3879\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8366 - accuracy: 0.5340 - val_loss: 1.2395 - val_accuracy: 0.4112\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8284 - accuracy: 0.5610 - val_loss: 1.2505 - val_accuracy: 0.4019\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8129 - accuracy: 0.5622 - val_loss: 1.2712 - val_accuracy: 0.3785\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8100 - accuracy: 0.5540 - val_loss: 1.2520 - val_accuracy: 0.3785\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8959 - accuracy: 0.5082 - val_loss: 1.2526 - val_accuracy: 0.3832\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8467 - accuracy: 0.5223 - val_loss: 1.2743 - val_accuracy: 0.3879\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8284 - accuracy: 0.5340 - val_loss: 1.2658 - val_accuracy: 0.4065\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8475 - accuracy: 0.5446 - val_loss: 1.2667 - val_accuracy: 0.3972\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8754 - accuracy: 0.5293 - val_loss: 1.2701 - val_accuracy: 0.3972\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8241 - accuracy: 0.5786 - val_loss: 1.2884 - val_accuracy: 0.3832\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8713 - accuracy: 0.5352 - val_loss: 1.2747 - val_accuracy: 0.3879\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8368 - accuracy: 0.5469 - val_loss: 1.2631 - val_accuracy: 0.3785\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8485 - accuracy: 0.5610 - val_loss: 1.2584 - val_accuracy: 0.3692\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8284 - accuracy: 0.5493 - val_loss: 1.2637 - val_accuracy: 0.3738\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8453 - accuracy: 0.5200 - val_loss: 1.2729 - val_accuracy: 0.3832\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8247 - accuracy: 0.5646 - val_loss: 1.2808 - val_accuracy: 0.3879\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8402 - accuracy: 0.5329 - val_loss: 1.2906 - val_accuracy: 0.3551\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8192 - accuracy: 0.5469 - val_loss: 1.2990 - val_accuracy: 0.3692\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8586 - accuracy: 0.5117 - val_loss: 1.2970 - val_accuracy: 0.3738\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8226 - accuracy: 0.5516 - val_loss: 1.2681 - val_accuracy: 0.3411\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8232 - accuracy: 0.5481 - val_loss: 1.2927 - val_accuracy: 0.3879\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8314 - accuracy: 0.5481 - val_loss: 1.3179 - val_accuracy: 0.4019\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8654 - accuracy: 0.5200 - val_loss: 1.3016 - val_accuracy: 0.4112\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8654 - accuracy: 0.5434 - val_loss: 1.2842 - val_accuracy: 0.3738\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8286 - accuracy: 0.5469 - val_loss: 1.2797 - val_accuracy: 0.3832\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8449 - accuracy: 0.5376 - val_loss: 1.2866 - val_accuracy: 0.3785\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8344 - accuracy: 0.5305 - val_loss: 1.2812 - val_accuracy: 0.3692\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8560 - accuracy: 0.5164 - val_loss: 1.2819 - val_accuracy: 0.3458\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8595 - accuracy: 0.5434 - val_loss: 1.2824 - val_accuracy: 0.3411\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8489 - accuracy: 0.5376 - val_loss: 1.2441 - val_accuracy: 0.3411\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8743 - accuracy: 0.5481 - val_loss: 1.2205 - val_accuracy: 0.3738\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8556 - accuracy: 0.5317 - val_loss: 1.2191 - val_accuracy: 0.3645\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8714 - accuracy: 0.5376 - val_loss: 1.2205 - val_accuracy: 0.3738\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8361 - accuracy: 0.5246 - val_loss: 1.2325 - val_accuracy: 0.3879\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8688 - accuracy: 0.5293 - val_loss: 1.2468 - val_accuracy: 0.3692\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8478 - accuracy: 0.5317 - val_loss: 1.2473 - val_accuracy: 0.3785\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8579 - accuracy: 0.5399 - val_loss: 1.2405 - val_accuracy: 0.3785\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8485 - accuracy: 0.5516 - val_loss: 1.2427 - val_accuracy: 0.3879\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8406 - accuracy: 0.5352 - val_loss: 1.2555 - val_accuracy: 0.3925\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8329 - accuracy: 0.5587 - val_loss: 1.2855 - val_accuracy: 0.3785\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8665 - accuracy: 0.5282 - val_loss: 1.2674 - val_accuracy: 0.3879\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8595 - accuracy: 0.5282 - val_loss: 1.2576 - val_accuracy: 0.3785\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8564 - accuracy: 0.5117 - val_loss: 1.2490 - val_accuracy: 0.3598\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8275 - accuracy: 0.5493 - val_loss: 1.2486 - val_accuracy: 0.3879\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8370 - accuracy: 0.5376 - val_loss: 1.2224 - val_accuracy: 0.3738\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8240 - accuracy: 0.5270 - val_loss: 1.2308 - val_accuracy: 0.3505\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8439 - accuracy: 0.5117 - val_loss: 1.2392 - val_accuracy: 0.3645\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8250 - accuracy: 0.5610 - val_loss: 1.2542 - val_accuracy: 0.3598\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8699 - accuracy: 0.5364 - val_loss: 1.2566 - val_accuracy: 0.3738\n",
            "Epoch 601/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.8130 - accuracy: 0.5833\n",
            "Epoch: 600, accuracy:0.5411,  loss:0.8588,  val_accuracy:0.3738,  val_loss:1.2642,  \n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8588 - accuracy: 0.5411 - val_loss: 1.2642 - val_accuracy: 0.3738\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8457 - accuracy: 0.5587 - val_loss: 1.2618 - val_accuracy: 0.3692\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8680 - accuracy: 0.5293 - val_loss: 1.2574 - val_accuracy: 0.3598\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8156 - accuracy: 0.5340 - val_loss: 1.2691 - val_accuracy: 0.3458\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8553 - accuracy: 0.5317 - val_loss: 1.2714 - val_accuracy: 0.3411\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8310 - accuracy: 0.5423 - val_loss: 1.2850 - val_accuracy: 0.3551\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8506 - accuracy: 0.5364 - val_loss: 1.2700 - val_accuracy: 0.3692\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8595 - accuracy: 0.5340 - val_loss: 1.2791 - val_accuracy: 0.3738\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8220 - accuracy: 0.5411 - val_loss: 1.2798 - val_accuracy: 0.3505\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8608 - accuracy: 0.5540 - val_loss: 1.2785 - val_accuracy: 0.3598\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8284 - accuracy: 0.5587 - val_loss: 1.2669 - val_accuracy: 0.3738\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8373 - accuracy: 0.5599 - val_loss: 1.2593 - val_accuracy: 0.3692\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8437 - accuracy: 0.5340 - val_loss: 1.2774 - val_accuracy: 0.3505\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8150 - accuracy: 0.5505 - val_loss: 1.2910 - val_accuracy: 0.3458\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8246 - accuracy: 0.5434 - val_loss: 1.2649 - val_accuracy: 0.3692\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8657 - accuracy: 0.5610 - val_loss: 1.2654 - val_accuracy: 0.3692\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8432 - accuracy: 0.5446 - val_loss: 1.2447 - val_accuracy: 0.3785\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8323 - accuracy: 0.5528 - val_loss: 1.2060 - val_accuracy: 0.3645\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8539 - accuracy: 0.5070 - val_loss: 1.2022 - val_accuracy: 0.3692\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8424 - accuracy: 0.5258 - val_loss: 1.2126 - val_accuracy: 0.3785\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8480 - accuracy: 0.5258 - val_loss: 1.2232 - val_accuracy: 0.3832\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8340 - accuracy: 0.5399 - val_loss: 1.2301 - val_accuracy: 0.3692\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8348 - accuracy: 0.5739 - val_loss: 1.2525 - val_accuracy: 0.3832\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8557 - accuracy: 0.5340 - val_loss: 1.2751 - val_accuracy: 0.3692\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7914 - accuracy: 0.5634 - val_loss: 1.2752 - val_accuracy: 0.3598\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8232 - accuracy: 0.5657 - val_loss: 1.2746 - val_accuracy: 0.3505\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8291 - accuracy: 0.5387 - val_loss: 1.2864 - val_accuracy: 0.3505\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8159 - accuracy: 0.5270 - val_loss: 1.3011 - val_accuracy: 0.3738\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8352 - accuracy: 0.4965 - val_loss: 1.3113 - val_accuracy: 0.3692\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8138 - accuracy: 0.5528 - val_loss: 1.3332 - val_accuracy: 0.3879\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8335 - accuracy: 0.5681 - val_loss: 1.3183 - val_accuracy: 0.3692\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8456 - accuracy: 0.5458 - val_loss: 1.2982 - val_accuracy: 0.3551\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8237 - accuracy: 0.5399 - val_loss: 1.3070 - val_accuracy: 0.3505\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8193 - accuracy: 0.5469 - val_loss: 1.3194 - val_accuracy: 0.3645\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8413 - accuracy: 0.5352 - val_loss: 1.3237 - val_accuracy: 0.3692\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8094 - accuracy: 0.5516 - val_loss: 1.3094 - val_accuracy: 0.3692\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8245 - accuracy: 0.5528 - val_loss: 1.2503 - val_accuracy: 0.3364\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8469 - accuracy: 0.5246 - val_loss: 1.2433 - val_accuracy: 0.3364\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8061 - accuracy: 0.5293 - val_loss: 1.2710 - val_accuracy: 0.3458\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8354 - accuracy: 0.5352 - val_loss: 1.2709 - val_accuracy: 0.3505\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8318 - accuracy: 0.5423 - val_loss: 1.2874 - val_accuracy: 0.3738\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8518 - accuracy: 0.5575 - val_loss: 1.2821 - val_accuracy: 0.3738\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8029 - accuracy: 0.5399 - val_loss: 1.2719 - val_accuracy: 0.3692\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8366 - accuracy: 0.5434 - val_loss: 1.2897 - val_accuracy: 0.3785\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8474 - accuracy: 0.5610 - val_loss: 1.3259 - val_accuracy: 0.3738\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8591 - accuracy: 0.5563 - val_loss: 1.3348 - val_accuracy: 0.3645\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8455 - accuracy: 0.5692 - val_loss: 1.2862 - val_accuracy: 0.3551\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8237 - accuracy: 0.5246 - val_loss: 1.2781 - val_accuracy: 0.3458\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8450 - accuracy: 0.5270 - val_loss: 1.2789 - val_accuracy: 0.3505\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8473 - accuracy: 0.5340 - val_loss: 1.3002 - val_accuracy: 0.3505\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8157 - accuracy: 0.5657 - val_loss: 1.3211 - val_accuracy: 0.3692\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8271 - accuracy: 0.5552 - val_loss: 1.3323 - val_accuracy: 0.3738\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8159 - accuracy: 0.5610 - val_loss: 1.2730 - val_accuracy: 0.3458\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8360 - accuracy: 0.5528 - val_loss: 1.2681 - val_accuracy: 0.3505\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8037 - accuracy: 0.5446 - val_loss: 1.2964 - val_accuracy: 0.3598\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8150 - accuracy: 0.5528 - val_loss: 1.3266 - val_accuracy: 0.3692\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7865 - accuracy: 0.5610 - val_loss: 1.3150 - val_accuracy: 0.3318\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8249 - accuracy: 0.5458 - val_loss: 1.3340 - val_accuracy: 0.3364\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8180 - accuracy: 0.5446 - val_loss: 1.3473 - val_accuracy: 0.3551\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8552 - accuracy: 0.5282 - val_loss: 1.3149 - val_accuracy: 0.3551\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8373 - accuracy: 0.5340 - val_loss: 1.2854 - val_accuracy: 0.3692\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8418 - accuracy: 0.5458 - val_loss: 1.2808 - val_accuracy: 0.3692\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8115 - accuracy: 0.5681 - val_loss: 1.2937 - val_accuracy: 0.3785\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8286 - accuracy: 0.5446 - val_loss: 1.2902 - val_accuracy: 0.3645\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8059 - accuracy: 0.5423 - val_loss: 1.2982 - val_accuracy: 0.3692\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8006 - accuracy: 0.5657 - val_loss: 1.3223 - val_accuracy: 0.3598\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8135 - accuracy: 0.5646 - val_loss: 1.3281 - val_accuracy: 0.3505\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.8118 - accuracy: 0.5833 - val_loss: 1.3309 - val_accuracy: 0.3692\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8240 - accuracy: 0.5575 - val_loss: 1.3388 - val_accuracy: 0.3598\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8546 - accuracy: 0.5516 - val_loss: 1.3081 - val_accuracy: 0.3505\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8299 - accuracy: 0.5246 - val_loss: 1.2952 - val_accuracy: 0.3645\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8167 - accuracy: 0.5423 - val_loss: 1.3067 - val_accuracy: 0.3598\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8112 - accuracy: 0.5458 - val_loss: 1.3100 - val_accuracy: 0.3551\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8441 - accuracy: 0.5411 - val_loss: 1.2926 - val_accuracy: 0.3505\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8281 - accuracy: 0.5411 - val_loss: 1.2999 - val_accuracy: 0.3785\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8420 - accuracy: 0.5423 - val_loss: 1.3150 - val_accuracy: 0.3972\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8437 - accuracy: 0.5293 - val_loss: 1.2986 - val_accuracy: 0.3879\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8363 - accuracy: 0.5434 - val_loss: 1.2892 - val_accuracy: 0.3785\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7903 - accuracy: 0.5681 - val_loss: 1.3036 - val_accuracy: 0.3738\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8203 - accuracy: 0.5458 - val_loss: 1.3270 - val_accuracy: 0.3785\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8206 - accuracy: 0.5634 - val_loss: 1.3485 - val_accuracy: 0.3738\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8452 - accuracy: 0.5528 - val_loss: 1.3449 - val_accuracy: 0.3832\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8574 - accuracy: 0.5552 - val_loss: 1.3171 - val_accuracy: 0.3645\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7860 - accuracy: 0.5528 - val_loss: 1.3341 - val_accuracy: 0.3505\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8464 - accuracy: 0.5434 - val_loss: 1.3392 - val_accuracy: 0.3692\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8038 - accuracy: 0.5634 - val_loss: 1.3390 - val_accuracy: 0.3692\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8184 - accuracy: 0.5540 - val_loss: 1.3513 - val_accuracy: 0.3551\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8320 - accuracy: 0.5352 - val_loss: 1.3639 - val_accuracy: 0.3505\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8312 - accuracy: 0.5493 - val_loss: 1.3539 - val_accuracy: 0.3785\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7779 - accuracy: 0.5646 - val_loss: 1.3589 - val_accuracy: 0.3879\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8278 - accuracy: 0.5622 - val_loss: 1.3706 - val_accuracy: 0.3972\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8100 - accuracy: 0.5728 - val_loss: 1.3631 - val_accuracy: 0.3972\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7891 - accuracy: 0.5634 - val_loss: 1.3645 - val_accuracy: 0.3832\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8182 - accuracy: 0.5458 - val_loss: 1.3625 - val_accuracy: 0.3505\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7794 - accuracy: 0.5610 - val_loss: 1.3736 - val_accuracy: 0.3411\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8249 - accuracy: 0.5669 - val_loss: 1.3807 - val_accuracy: 0.3598\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8288 - accuracy: 0.5528 - val_loss: 1.3616 - val_accuracy: 0.3645\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7809 - accuracy: 0.5552 - val_loss: 1.3555 - val_accuracy: 0.3505\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8136 - accuracy: 0.5329 - val_loss: 1.3588 - val_accuracy: 0.3505\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8235 - accuracy: 0.5446 - val_loss: 1.3628 - val_accuracy: 0.3598\n",
            "Epoch 701/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.8331 - accuracy: 0.5583\n",
            "Epoch: 700, accuracy:0.5751,  loss:0.7783,  val_accuracy:0.3832,  val_loss:1.3170,  \n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7783 - accuracy: 0.5751 - val_loss: 1.3170 - val_accuracy: 0.3832\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8156 - accuracy: 0.5728 - val_loss: 1.3176 - val_accuracy: 0.3738\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8027 - accuracy: 0.5728 - val_loss: 1.3216 - val_accuracy: 0.3458\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7958 - accuracy: 0.5434 - val_loss: 1.3359 - val_accuracy: 0.3692\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7899 - accuracy: 0.5763 - val_loss: 1.3532 - val_accuracy: 0.3598\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8097 - accuracy: 0.5552 - val_loss: 1.3658 - val_accuracy: 0.3879\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7886 - accuracy: 0.5728 - val_loss: 1.3593 - val_accuracy: 0.3785\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8142 - accuracy: 0.5352 - val_loss: 1.3431 - val_accuracy: 0.3738\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7930 - accuracy: 0.5857 - val_loss: 1.3172 - val_accuracy: 0.3692\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8023 - accuracy: 0.5681 - val_loss: 1.3207 - val_accuracy: 0.3645\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8061 - accuracy: 0.5446 - val_loss: 1.3094 - val_accuracy: 0.3645\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8025 - accuracy: 0.5622 - val_loss: 1.3175 - val_accuracy: 0.3598\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8113 - accuracy: 0.5317 - val_loss: 1.3267 - val_accuracy: 0.3411\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7995 - accuracy: 0.5622 - val_loss: 1.3180 - val_accuracy: 0.3411\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7823 - accuracy: 0.5481 - val_loss: 1.3436 - val_accuracy: 0.3551\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7800 - accuracy: 0.5775 - val_loss: 1.3695 - val_accuracy: 0.3411\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8181 - accuracy: 0.5516 - val_loss: 1.3360 - val_accuracy: 0.3318\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8473 - accuracy: 0.5387 - val_loss: 1.3382 - val_accuracy: 0.3411\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8481 - accuracy: 0.5493 - val_loss: 1.3528 - val_accuracy: 0.3505\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7927 - accuracy: 0.5669 - val_loss: 1.3344 - val_accuracy: 0.3411\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8234 - accuracy: 0.5364 - val_loss: 1.2975 - val_accuracy: 0.3318\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8148 - accuracy: 0.5610 - val_loss: 1.2964 - val_accuracy: 0.3505\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7862 - accuracy: 0.5575 - val_loss: 1.3114 - val_accuracy: 0.3551\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8071 - accuracy: 0.5681 - val_loss: 1.3418 - val_accuracy: 0.3505\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7983 - accuracy: 0.5657 - val_loss: 1.3491 - val_accuracy: 0.3505\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8122 - accuracy: 0.5657 - val_loss: 1.3461 - val_accuracy: 0.3458\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7998 - accuracy: 0.5704 - val_loss: 1.3511 - val_accuracy: 0.3598\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7929 - accuracy: 0.5763 - val_loss: 1.3505 - val_accuracy: 0.3411\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8252 - accuracy: 0.5528 - val_loss: 1.3598 - val_accuracy: 0.3598\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8280 - accuracy: 0.5728 - val_loss: 1.3580 - val_accuracy: 0.3505\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.7834 - accuracy: 0.5904 - val_loss: 1.3545 - val_accuracy: 0.3458\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8062 - accuracy: 0.5563 - val_loss: 1.3508 - val_accuracy: 0.3411\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7990 - accuracy: 0.5704 - val_loss: 1.3509 - val_accuracy: 0.3411\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7964 - accuracy: 0.5622 - val_loss: 1.3647 - val_accuracy: 0.3364\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8086 - accuracy: 0.5352 - val_loss: 1.3994 - val_accuracy: 0.3598\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7831 - accuracy: 0.5657 - val_loss: 1.3955 - val_accuracy: 0.3645\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7772 - accuracy: 0.5904 - val_loss: 1.3818 - val_accuracy: 0.3645\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8472 - accuracy: 0.5469 - val_loss: 1.3653 - val_accuracy: 0.3598\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8254 - accuracy: 0.5516 - val_loss: 1.3841 - val_accuracy: 0.3551\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7709 - accuracy: 0.5540 - val_loss: 1.3987 - val_accuracy: 0.3692\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7898 - accuracy: 0.5704 - val_loss: 1.3940 - val_accuracy: 0.3551\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8105 - accuracy: 0.5786 - val_loss: 1.3875 - val_accuracy: 0.3364\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8299 - accuracy: 0.5587 - val_loss: 1.3825 - val_accuracy: 0.3131\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8167 - accuracy: 0.5411 - val_loss: 1.3767 - val_accuracy: 0.3131\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8345 - accuracy: 0.5352 - val_loss: 1.3836 - val_accuracy: 0.3224\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8507 - accuracy: 0.5434 - val_loss: 1.3879 - val_accuracy: 0.3551\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8331 - accuracy: 0.5528 - val_loss: 1.3725 - val_accuracy: 0.3411\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7825 - accuracy: 0.5528 - val_loss: 1.3706 - val_accuracy: 0.3598\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7663 - accuracy: 0.5657 - val_loss: 1.3880 - val_accuracy: 0.3738\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7919 - accuracy: 0.5822 - val_loss: 1.4085 - val_accuracy: 0.3738\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7972 - accuracy: 0.5739 - val_loss: 1.4147 - val_accuracy: 0.3879\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7810 - accuracy: 0.5833 - val_loss: 1.4128 - val_accuracy: 0.3785\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7942 - accuracy: 0.5587 - val_loss: 1.4000 - val_accuracy: 0.3972\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8196 - accuracy: 0.5599 - val_loss: 1.3670 - val_accuracy: 0.3598\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8114 - accuracy: 0.5505 - val_loss: 1.3786 - val_accuracy: 0.3692\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8081 - accuracy: 0.5505 - val_loss: 1.3510 - val_accuracy: 0.3551\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8145 - accuracy: 0.5810 - val_loss: 1.3515 - val_accuracy: 0.3551\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7926 - accuracy: 0.5692 - val_loss: 1.3640 - val_accuracy: 0.3645\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8185 - accuracy: 0.5528 - val_loss: 1.3658 - val_accuracy: 0.3598\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8040 - accuracy: 0.5469 - val_loss: 1.3700 - val_accuracy: 0.3598\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7875 - accuracy: 0.5505 - val_loss: 1.3793 - val_accuracy: 0.3879\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7581 - accuracy: 0.5833 - val_loss: 1.3828 - val_accuracy: 0.3832\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8329 - accuracy: 0.5763 - val_loss: 1.3500 - val_accuracy: 0.3598\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8165 - accuracy: 0.5340 - val_loss: 1.3254 - val_accuracy: 0.3832\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7837 - accuracy: 0.5775 - val_loss: 1.3167 - val_accuracy: 0.3832\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7979 - accuracy: 0.5599 - val_loss: 1.3339 - val_accuracy: 0.3738\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7742 - accuracy: 0.6021 - val_loss: 1.3748 - val_accuracy: 0.3738\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8137 - accuracy: 0.5739 - val_loss: 1.3952 - val_accuracy: 0.3832\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7763 - accuracy: 0.5528 - val_loss: 1.3903 - val_accuracy: 0.3785\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7870 - accuracy: 0.5423 - val_loss: 1.3840 - val_accuracy: 0.3785\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7990 - accuracy: 0.5552 - val_loss: 1.4193 - val_accuracy: 0.3692\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7870 - accuracy: 0.5692 - val_loss: 1.4343 - val_accuracy: 0.3879\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7848 - accuracy: 0.5692 - val_loss: 1.4342 - val_accuracy: 0.3879\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7770 - accuracy: 0.5822 - val_loss: 1.4007 - val_accuracy: 0.3738\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7898 - accuracy: 0.5516 - val_loss: 1.3388 - val_accuracy: 0.3598\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8011 - accuracy: 0.5810 - val_loss: 1.3481 - val_accuracy: 0.3692\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7875 - accuracy: 0.5716 - val_loss: 1.3645 - val_accuracy: 0.3645\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8450 - accuracy: 0.5364 - val_loss: 1.3647 - val_accuracy: 0.3692\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7970 - accuracy: 0.5399 - val_loss: 1.3688 - val_accuracy: 0.3598\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8120 - accuracy: 0.5469 - val_loss: 1.3609 - val_accuracy: 0.3785\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7465 - accuracy: 0.5833 - val_loss: 1.3815 - val_accuracy: 0.3879\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7629 - accuracy: 0.5915 - val_loss: 1.4096 - val_accuracy: 0.3785\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8142 - accuracy: 0.5399 - val_loss: 1.3918 - val_accuracy: 0.3738\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8490 - accuracy: 0.5716 - val_loss: 1.3633 - val_accuracy: 0.3738\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7986 - accuracy: 0.5646 - val_loss: 1.3561 - val_accuracy: 0.4019\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7758 - accuracy: 0.5892 - val_loss: 1.3608 - val_accuracy: 0.3879\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7682 - accuracy: 0.5810 - val_loss: 1.3358 - val_accuracy: 0.3645\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7550 - accuracy: 0.5681 - val_loss: 1.3476 - val_accuracy: 0.3925\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7761 - accuracy: 0.5974 - val_loss: 1.3588 - val_accuracy: 0.3738\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8038 - accuracy: 0.5540 - val_loss: 1.3635 - val_accuracy: 0.3738\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7953 - accuracy: 0.5646 - val_loss: 1.3887 - val_accuracy: 0.3972\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7841 - accuracy: 0.5669 - val_loss: 1.3964 - val_accuracy: 0.3972\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7662 - accuracy: 0.5763 - val_loss: 1.3926 - val_accuracy: 0.3692\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7555 - accuracy: 0.5939 - val_loss: 1.3921 - val_accuracy: 0.3411\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7685 - accuracy: 0.5728 - val_loss: 1.3861 - val_accuracy: 0.3738\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7432 - accuracy: 0.6021 - val_loss: 1.3939 - val_accuracy: 0.3879\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7897 - accuracy: 0.5528 - val_loss: 1.3972 - val_accuracy: 0.3925\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7941 - accuracy: 0.5446 - val_loss: 1.4253 - val_accuracy: 0.3879\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7531 - accuracy: 0.5927 - val_loss: 1.4482 - val_accuracy: 0.3785\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7757 - accuracy: 0.5681 - val_loss: 1.4577 - val_accuracy: 0.3785\n",
            "Epoch 801/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.8293 - accuracy: 0.5917\n",
            "Epoch: 800, accuracy:0.6068,  loss:0.7524,  val_accuracy:0.3879,  val_loss:1.4408,  \n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7524 - accuracy: 0.6068 - val_loss: 1.4408 - val_accuracy: 0.3879\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7794 - accuracy: 0.5751 - val_loss: 1.4287 - val_accuracy: 0.3832\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7763 - accuracy: 0.5845 - val_loss: 1.4328 - val_accuracy: 0.3879\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7439 - accuracy: 0.6056 - val_loss: 1.4377 - val_accuracy: 0.3972\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7942 - accuracy: 0.5681 - val_loss: 1.4316 - val_accuracy: 0.3645\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7837 - accuracy: 0.5739 - val_loss: 1.4304 - val_accuracy: 0.3785\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8034 - accuracy: 0.5516 - val_loss: 1.4085 - val_accuracy: 0.3692\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8132 - accuracy: 0.5681 - val_loss: 1.4198 - val_accuracy: 0.3972\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8094 - accuracy: 0.5423 - val_loss: 1.4220 - val_accuracy: 0.3925\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8091 - accuracy: 0.5634 - val_loss: 1.4194 - val_accuracy: 0.3785\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7879 - accuracy: 0.5892 - val_loss: 1.3943 - val_accuracy: 0.3879\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7837 - accuracy: 0.5751 - val_loss: 1.3843 - val_accuracy: 0.3785\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7891 - accuracy: 0.5810 - val_loss: 1.3757 - val_accuracy: 0.3879\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7771 - accuracy: 0.5716 - val_loss: 1.3665 - val_accuracy: 0.3645\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8079 - accuracy: 0.5857 - val_loss: 1.3857 - val_accuracy: 0.3832\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7730 - accuracy: 0.5775 - val_loss: 1.3865 - val_accuracy: 0.3785\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7657 - accuracy: 0.5904 - val_loss: 1.3928 - val_accuracy: 0.3692\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7658 - accuracy: 0.5669 - val_loss: 1.4034 - val_accuracy: 0.3832\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7698 - accuracy: 0.5986 - val_loss: 1.4140 - val_accuracy: 0.3879\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8290 - accuracy: 0.5822 - val_loss: 1.3920 - val_accuracy: 0.3879\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7862 - accuracy: 0.5716 - val_loss: 1.3632 - val_accuracy: 0.3879\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8148 - accuracy: 0.5622 - val_loss: 1.3475 - val_accuracy: 0.3785\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7670 - accuracy: 0.5951 - val_loss: 1.3739 - val_accuracy: 0.3738\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7964 - accuracy: 0.5822 - val_loss: 1.4070 - val_accuracy: 0.3925\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8048 - accuracy: 0.5775 - val_loss: 1.3915 - val_accuracy: 0.3785\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7570 - accuracy: 0.5728 - val_loss: 1.3535 - val_accuracy: 0.3692\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7717 - accuracy: 0.5775 - val_loss: 1.3696 - val_accuracy: 0.3598\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7739 - accuracy: 0.5857 - val_loss: 1.4046 - val_accuracy: 0.3832\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7888 - accuracy: 0.5915 - val_loss: 1.3906 - val_accuracy: 0.3925\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7877 - accuracy: 0.5739 - val_loss: 1.3910 - val_accuracy: 0.3879\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7934 - accuracy: 0.5786 - val_loss: 1.4006 - val_accuracy: 0.3785\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7340 - accuracy: 0.5962 - val_loss: 1.4123 - val_accuracy: 0.3832\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7671 - accuracy: 0.5716 - val_loss: 1.4295 - val_accuracy: 0.3738\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7832 - accuracy: 0.5669 - val_loss: 1.4514 - val_accuracy: 0.3972\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8189 - accuracy: 0.5481 - val_loss: 1.4246 - val_accuracy: 0.3832\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7517 - accuracy: 0.6080 - val_loss: 1.3994 - val_accuracy: 0.3598\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7629 - accuracy: 0.5634 - val_loss: 1.3990 - val_accuracy: 0.3785\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8036 - accuracy: 0.5599 - val_loss: 1.4129 - val_accuracy: 0.3785\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7893 - accuracy: 0.5646 - val_loss: 1.4295 - val_accuracy: 0.3832\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7696 - accuracy: 0.5763 - val_loss: 1.4439 - val_accuracy: 0.3738\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7434 - accuracy: 0.6056 - val_loss: 1.4362 - val_accuracy: 0.3832\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7412 - accuracy: 0.5869 - val_loss: 1.4420 - val_accuracy: 0.3692\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7963 - accuracy: 0.5634 - val_loss: 1.4320 - val_accuracy: 0.3598\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7956 - accuracy: 0.5986 - val_loss: 1.4265 - val_accuracy: 0.3458\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.7902 - accuracy: 0.5763 - val_loss: 1.4171 - val_accuracy: 0.3645\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8117 - accuracy: 0.5599 - val_loss: 1.3801 - val_accuracy: 0.3692\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7751 - accuracy: 0.5434 - val_loss: 1.3271 - val_accuracy: 0.3832\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7863 - accuracy: 0.5528 - val_loss: 1.3198 - val_accuracy: 0.3879\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7692 - accuracy: 0.5798 - val_loss: 1.3474 - val_accuracy: 0.3925\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7790 - accuracy: 0.5763 - val_loss: 1.3528 - val_accuracy: 0.3972\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8113 - accuracy: 0.5399 - val_loss: 1.3670 - val_accuracy: 0.3972\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7463 - accuracy: 0.5927 - val_loss: 1.3969 - val_accuracy: 0.3879\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7562 - accuracy: 0.5610 - val_loss: 1.4286 - val_accuracy: 0.3879\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.7913 - accuracy: 0.5552 - val_loss: 1.3992 - val_accuracy: 0.3879\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7698 - accuracy: 0.5622 - val_loss: 1.4124 - val_accuracy: 0.3738\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7354 - accuracy: 0.5939 - val_loss: 1.4356 - val_accuracy: 0.3785\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7604 - accuracy: 0.5951 - val_loss: 1.4590 - val_accuracy: 0.3925\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7500 - accuracy: 0.6162 - val_loss: 1.4721 - val_accuracy: 0.4019\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7273 - accuracy: 0.6150 - val_loss: 1.4446 - val_accuracy: 0.3972\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7396 - accuracy: 0.6033 - val_loss: 1.4756 - val_accuracy: 0.4065\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7872 - accuracy: 0.5845 - val_loss: 1.4796 - val_accuracy: 0.4159\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7448 - accuracy: 0.5822 - val_loss: 1.4955 - val_accuracy: 0.4112\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7518 - accuracy: 0.6127 - val_loss: 1.4943 - val_accuracy: 0.4112\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7725 - accuracy: 0.6080 - val_loss: 1.4914 - val_accuracy: 0.4065\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7594 - accuracy: 0.5810 - val_loss: 1.4839 - val_accuracy: 0.3692\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7689 - accuracy: 0.5822 - val_loss: 1.4755 - val_accuracy: 0.3692\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7792 - accuracy: 0.5622 - val_loss: 1.4582 - val_accuracy: 0.3692\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7537 - accuracy: 0.5822 - val_loss: 1.4682 - val_accuracy: 0.3645\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7304 - accuracy: 0.5927 - val_loss: 1.4714 - val_accuracy: 0.3505\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7539 - accuracy: 0.5869 - val_loss: 1.4685 - val_accuracy: 0.3645\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7674 - accuracy: 0.5833 - val_loss: 1.4728 - val_accuracy: 0.3692\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7611 - accuracy: 0.5798 - val_loss: 1.4464 - val_accuracy: 0.3738\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7855 - accuracy: 0.5892 - val_loss: 1.4487 - val_accuracy: 0.3832\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7719 - accuracy: 0.5716 - val_loss: 1.4567 - val_accuracy: 0.3692\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7730 - accuracy: 0.5775 - val_loss: 1.4516 - val_accuracy: 0.3785\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8152 - accuracy: 0.5810 - val_loss: 1.4115 - val_accuracy: 0.3645\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7595 - accuracy: 0.6045 - val_loss: 1.4113 - val_accuracy: 0.3692\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7341 - accuracy: 0.5986 - val_loss: 1.4345 - val_accuracy: 0.3832\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8069 - accuracy: 0.5763 - val_loss: 1.4438 - val_accuracy: 0.3879\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7888 - accuracy: 0.5681 - val_loss: 1.4366 - val_accuracy: 0.3738\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7956 - accuracy: 0.5657 - val_loss: 1.4422 - val_accuracy: 0.3832\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.7496 - accuracy: 0.5857 - val_loss: 1.4319 - val_accuracy: 0.3832\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7647 - accuracy: 0.6021 - val_loss: 1.4465 - val_accuracy: 0.3692\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7826 - accuracy: 0.5798 - val_loss: 1.4481 - val_accuracy: 0.3692\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7698 - accuracy: 0.5833 - val_loss: 1.4021 - val_accuracy: 0.3645\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7771 - accuracy: 0.5657 - val_loss: 1.4069 - val_accuracy: 0.3785\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7908 - accuracy: 0.5552 - val_loss: 1.3943 - val_accuracy: 0.3785\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8208 - accuracy: 0.5692 - val_loss: 1.3839 - val_accuracy: 0.3738\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8116 - accuracy: 0.5458 - val_loss: 1.3458 - val_accuracy: 0.3645\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8053 - accuracy: 0.5434 - val_loss: 1.3722 - val_accuracy: 0.3598\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.8218 - accuracy: 0.5364 - val_loss: 1.4060 - val_accuracy: 0.3505\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8158 - accuracy: 0.5446 - val_loss: 1.4018 - val_accuracy: 0.3551\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8087 - accuracy: 0.5775 - val_loss: 1.3641 - val_accuracy: 0.3598\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7794 - accuracy: 0.5775 - val_loss: 1.3682 - val_accuracy: 0.3551\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8130 - accuracy: 0.5692 - val_loss: 1.3782 - val_accuracy: 0.3505\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7663 - accuracy: 0.5810 - val_loss: 1.3901 - val_accuracy: 0.3505\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7606 - accuracy: 0.5880 - val_loss: 1.3954 - val_accuracy: 0.3645\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7543 - accuracy: 0.5692 - val_loss: 1.3925 - val_accuracy: 0.3645\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7589 - accuracy: 0.5951 - val_loss: 1.3878 - val_accuracy: 0.3598\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8164 - accuracy: 0.5669 - val_loss: 1.3677 - val_accuracy: 0.3598\n",
            "Epoch 901/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.8011 - accuracy: 0.5750\n",
            "Epoch: 900, accuracy:0.5892,  loss:0.7426,  val_accuracy:0.3785,  val_loss:1.3207,  \n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7426 - accuracy: 0.5892 - val_loss: 1.3207 - val_accuracy: 0.3785\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7925 - accuracy: 0.5681 - val_loss: 1.3191 - val_accuracy: 0.4065\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7416 - accuracy: 0.6127 - val_loss: 1.3593 - val_accuracy: 0.3879\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7709 - accuracy: 0.5845 - val_loss: 1.3931 - val_accuracy: 0.3785\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7514 - accuracy: 0.5692 - val_loss: 1.4052 - val_accuracy: 0.3645\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7890 - accuracy: 0.5763 - val_loss: 1.4164 - val_accuracy: 0.3738\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7645 - accuracy: 0.5845 - val_loss: 1.3910 - val_accuracy: 0.3411\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7345 - accuracy: 0.6021 - val_loss: 1.3865 - val_accuracy: 0.3598\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8177 - accuracy: 0.5599 - val_loss: 1.3918 - val_accuracy: 0.3925\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7540 - accuracy: 0.6127 - val_loss: 1.3865 - val_accuracy: 0.4019\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.8032 - accuracy: 0.5681 - val_loss: 1.3723 - val_accuracy: 0.4019\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7418 - accuracy: 0.5962 - val_loss: 1.3866 - val_accuracy: 0.3972\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7438 - accuracy: 0.6209 - val_loss: 1.4006 - val_accuracy: 0.4019\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7492 - accuracy: 0.5951 - val_loss: 1.4058 - val_accuracy: 0.3972\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7573 - accuracy: 0.6150 - val_loss: 1.3980 - val_accuracy: 0.3879\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7193 - accuracy: 0.6056 - val_loss: 1.4198 - val_accuracy: 0.3551\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7739 - accuracy: 0.5587 - val_loss: 1.4474 - val_accuracy: 0.3458\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7321 - accuracy: 0.5927 - val_loss: 1.4650 - val_accuracy: 0.3598\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7646 - accuracy: 0.5986 - val_loss: 1.4764 - val_accuracy: 0.4019\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7589 - accuracy: 0.5845 - val_loss: 1.4720 - val_accuracy: 0.3879\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7625 - accuracy: 0.6056 - val_loss: 1.4229 - val_accuracy: 0.3785\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7479 - accuracy: 0.6068 - val_loss: 1.4089 - val_accuracy: 0.3598\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7564 - accuracy: 0.5810 - val_loss: 1.4183 - val_accuracy: 0.3505\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7585 - accuracy: 0.5798 - val_loss: 1.4416 - val_accuracy: 0.3505\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7259 - accuracy: 0.5951 - val_loss: 1.4314 - val_accuracy: 0.3505\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7362 - accuracy: 0.6045 - val_loss: 1.4278 - val_accuracy: 0.3505\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7433 - accuracy: 0.5939 - val_loss: 1.4560 - val_accuracy: 0.3458\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7315 - accuracy: 0.5974 - val_loss: 1.4961 - val_accuracy: 0.3458\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.8074 - accuracy: 0.5833 - val_loss: 1.4934 - val_accuracy: 0.3645\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7739 - accuracy: 0.5798 - val_loss: 1.4597 - val_accuracy: 0.3505\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7377 - accuracy: 0.5962 - val_loss: 1.4763 - val_accuracy: 0.3879\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7766 - accuracy: 0.5927 - val_loss: 1.4623 - val_accuracy: 0.3551\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7690 - accuracy: 0.6045 - val_loss: 1.4651 - val_accuracy: 0.3551\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7437 - accuracy: 0.5810 - val_loss: 1.4662 - val_accuracy: 0.3925\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7570 - accuracy: 0.6092 - val_loss: 1.4397 - val_accuracy: 0.3832\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7233 - accuracy: 0.5915 - val_loss: 1.4241 - val_accuracy: 0.3645\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7478 - accuracy: 0.5798 - val_loss: 1.4326 - val_accuracy: 0.3551\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7695 - accuracy: 0.5798 - val_loss: 1.4704 - val_accuracy: 0.3832\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7784 - accuracy: 0.5833 - val_loss: 1.4717 - val_accuracy: 0.3785\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7919 - accuracy: 0.5751 - val_loss: 1.4264 - val_accuracy: 0.3598\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7401 - accuracy: 0.5998 - val_loss: 1.4385 - val_accuracy: 0.3692\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7736 - accuracy: 0.5951 - val_loss: 1.4561 - val_accuracy: 0.3925\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7799 - accuracy: 0.5845 - val_loss: 1.4825 - val_accuracy: 0.3879\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7573 - accuracy: 0.6068 - val_loss: 1.4794 - val_accuracy: 0.3551\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7323 - accuracy: 0.5951 - val_loss: 1.4502 - val_accuracy: 0.3551\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7749 - accuracy: 0.5927 - val_loss: 1.4389 - val_accuracy: 0.3505\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7583 - accuracy: 0.5751 - val_loss: 1.4298 - val_accuracy: 0.3551\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7804 - accuracy: 0.5599 - val_loss: 1.4306 - val_accuracy: 0.3832\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7532 - accuracy: 0.6009 - val_loss: 1.4268 - val_accuracy: 0.3645\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7782 - accuracy: 0.5951 - val_loss: 1.4140 - val_accuracy: 0.3785\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7847 - accuracy: 0.6009 - val_loss: 1.4043 - val_accuracy: 0.3785\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7397 - accuracy: 0.5822 - val_loss: 1.4094 - val_accuracy: 0.3925\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7495 - accuracy: 0.6174 - val_loss: 1.4249 - val_accuracy: 0.3879\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8126 - accuracy: 0.5810 - val_loss: 1.4129 - val_accuracy: 0.3692\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7521 - accuracy: 0.5939 - val_loss: 1.4216 - val_accuracy: 0.3551\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7718 - accuracy: 0.5786 - val_loss: 1.4089 - val_accuracy: 0.3411\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7606 - accuracy: 0.5786 - val_loss: 1.4312 - val_accuracy: 0.3551\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8057 - accuracy: 0.5739 - val_loss: 1.4083 - val_accuracy: 0.3598\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7658 - accuracy: 0.5904 - val_loss: 1.4011 - val_accuracy: 0.3458\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7636 - accuracy: 0.5786 - val_loss: 1.4027 - val_accuracy: 0.3271\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7382 - accuracy: 0.5857 - val_loss: 1.4253 - val_accuracy: 0.3458\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7724 - accuracy: 0.5810 - val_loss: 1.4410 - val_accuracy: 0.3458\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7510 - accuracy: 0.5810 - val_loss: 1.4493 - val_accuracy: 0.3598\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7594 - accuracy: 0.6162 - val_loss: 1.4324 - val_accuracy: 0.3411\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7438 - accuracy: 0.5763 - val_loss: 1.4212 - val_accuracy: 0.3458\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7532 - accuracy: 0.6185 - val_loss: 1.4175 - val_accuracy: 0.3598\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7282 - accuracy: 0.5915 - val_loss: 1.4219 - val_accuracy: 0.3505\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7511 - accuracy: 0.5704 - val_loss: 1.4408 - val_accuracy: 0.3738\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7584 - accuracy: 0.5974 - val_loss: 1.4272 - val_accuracy: 0.3458\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7732 - accuracy: 0.5833 - val_loss: 1.4268 - val_accuracy: 0.3411\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7689 - accuracy: 0.5634 - val_loss: 1.4468 - val_accuracy: 0.3458\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7653 - accuracy: 0.5822 - val_loss: 1.4688 - val_accuracy: 0.3738\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7643 - accuracy: 0.6150 - val_loss: 1.4744 - val_accuracy: 0.3692\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7759 - accuracy: 0.5822 - val_loss: 1.4657 - val_accuracy: 0.3738\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7446 - accuracy: 0.6056 - val_loss: 1.4660 - val_accuracy: 0.3738\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7531 - accuracy: 0.5951 - val_loss: 1.4630 - val_accuracy: 0.3645\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7531 - accuracy: 0.5915 - val_loss: 1.4364 - val_accuracy: 0.3598\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7450 - accuracy: 0.5833 - val_loss: 1.4362 - val_accuracy: 0.3972\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7587 - accuracy: 0.5810 - val_loss: 1.4298 - val_accuracy: 0.3645\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7167 - accuracy: 0.6138 - val_loss: 1.4126 - val_accuracy: 0.3505\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8059 - accuracy: 0.5716 - val_loss: 1.4358 - val_accuracy: 0.3645\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7603 - accuracy: 0.5857 - val_loss: 1.4282 - val_accuracy: 0.3645\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7455 - accuracy: 0.5739 - val_loss: 1.4384 - val_accuracy: 0.3925\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7689 - accuracy: 0.6021 - val_loss: 1.4447 - val_accuracy: 0.4019\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7395 - accuracy: 0.5915 - val_loss: 1.4368 - val_accuracy: 0.3879\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7576 - accuracy: 0.5904 - val_loss: 1.4185 - val_accuracy: 0.3692\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7589 - accuracy: 0.6045 - val_loss: 1.4193 - val_accuracy: 0.3645\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7542 - accuracy: 0.5810 - val_loss: 1.3719 - val_accuracy: 0.3551\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7523 - accuracy: 0.5739 - val_loss: 1.3927 - val_accuracy: 0.4065\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7527 - accuracy: 0.5986 - val_loss: 1.4464 - val_accuracy: 0.4065\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7579 - accuracy: 0.6009 - val_loss: 1.4406 - val_accuracy: 0.4159\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7292 - accuracy: 0.6244 - val_loss: 1.4334 - val_accuracy: 0.4159\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.7538 - accuracy: 0.5951 - val_loss: 1.4283 - val_accuracy: 0.4299\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.6978 - accuracy: 0.5962 - val_loss: 1.4350 - val_accuracy: 0.4112\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.7401 - accuracy: 0.6056 - val_loss: 1.4343 - val_accuracy: 0.4065\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7792 - accuracy: 0.5880 - val_loss: 1.4517 - val_accuracy: 0.3972\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7396 - accuracy: 0.6033 - val_loss: 1.4646 - val_accuracy: 0.4112\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7318 - accuracy: 0.6315 - val_loss: 1.4645 - val_accuracy: 0.3972\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7198 - accuracy: 0.5927 - val_loss: 1.4570 - val_accuracy: 0.4019\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.7286 - accuracy: 0.5998 - val_loss: 1.4521 - val_accuracy: 0.3925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODHW1NAOqNcK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "38897578-28ba-4852-a0c1-ee96c134efde"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.779189</td>\n",
              "      <td>0.588028</td>\n",
              "      <td>1.451715</td>\n",
              "      <td>0.397196</td>\n",
              "      <td>995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0.739589</td>\n",
              "      <td>0.603286</td>\n",
              "      <td>1.464613</td>\n",
              "      <td>0.411215</td>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.731846</td>\n",
              "      <td>0.631455</td>\n",
              "      <td>1.464451</td>\n",
              "      <td>0.397196</td>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0.719753</td>\n",
              "      <td>0.592723</td>\n",
              "      <td>1.456988</td>\n",
              "      <td>0.401869</td>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.728607</td>\n",
              "      <td>0.599765</td>\n",
              "      <td>1.452050</td>\n",
              "      <td>0.392523</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  accuracy  val_loss  val_accuracy  epoch\n",
              "995  0.779189  0.588028  1.451715      0.397196    995\n",
              "996  0.739589  0.603286  1.464613      0.411215    996\n",
              "997  0.731846  0.631455  1.464451      0.397196    997\n",
              "998  0.719753  0.592723  1.456988      0.401869    998\n",
              "999  0.728607  0.599765  1.452050      0.392523    999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3-cFZIRrMKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "ed811a2d-5705-4171-e700-ac20e5aed7df"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "hist=history.history\n",
        "\n",
        "fig=plt.figure(figsize=(12,5))\n",
        "ax=fig.add_subplot(1,2,1)\n",
        "ax.plot(hist['loss'],lw=3)\n",
        "ax.plot(hist['val_loss'],lw=3)\n",
        "ax.set_title('Training & Validation Loss',size=15)\n",
        "ax.set_xlabel('Epoch',size=15)\n",
        "ax.tick_params(axis='both',which='major',labelsize=15)\n",
        "ax=fig.add_subplot(1,2,2)\n",
        "ax.plot(hist['accuracy'],lw=3)\n",
        "ax.plot(hist['val_accuracy'],lw=3)\n",
        "ax.set_title('Training & Validation accuracy',size=15)\n",
        "ax.set_xlabel('Epoch',size=15)\n",
        "ax.tick_params(axis='both',which='major',labelsize=15)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}